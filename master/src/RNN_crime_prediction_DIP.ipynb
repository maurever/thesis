{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import theano\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "raster = 200\n",
    "crime_type = \"E05\"\n",
    "date_from = \"2013-06-16\"\n",
    "date_to = \"2017-03-08\"\n",
    "\n",
    "days = 21\n",
    "dist = 5\n",
    "\n",
    "\n",
    "# insert main dir\n",
    "main_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as col\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import copy\n",
    "\n",
    "from numpy.ma import masked_array\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "startcolor = '#fff2e5'\n",
    "midcolor = '#f2a285'\n",
    "endcolor = '#c40d21'    \n",
    "cmap1 = col.LinearSegmentedColormap.from_list('own1',[startcolor,midcolor,endcolor])\n",
    "plt.cm.register_cmap(name = 'wrong', cmap=cmap1)\n",
    "\n",
    "startcolor = '#f3ffe5' \n",
    "midcolor = '#b4f185'   \n",
    "endcolor = 'darkgreen'   \n",
    "cmap2 = col.LinearSegmentedColormap.from_list('own2',[startcolor,midcolor,endcolor])\n",
    "plt.cm.register_cmap(name = 'correct', cmap=cmap2)\n",
    "\n",
    "classes=[0,1]\n",
    "\n",
    "def find_max_mcc_threshold(true_values, predictions, thresholds):\n",
    "    max_mcc = -1\n",
    "    max_threshold = thresholds[0]\n",
    "    max_predictions = predictions[:]\n",
    "    stop = 0\n",
    "    for i in range(1,thresholds.shape[0]):\n",
    "        tmp_threshold = thresholds[i]\n",
    "        tmp_predictions = copy.deepcopy(predictions)\n",
    "        tmp_predictions[tmp_predictions >= tmp_threshold] = int(1)\n",
    "        tmp_predictions[tmp_predictions < 1] = int(0)\n",
    "        tmp_mcc = matthews_corrcoef(true_values, tmp_predictions)\n",
    "        if tmp_mcc > max_mcc:\n",
    "            max_mcc = tmp_mcc\n",
    "            max_threshold = tmp_threshold\n",
    "            max_predictions = copy.deepcopy(tmp_predictions)\n",
    "            stop = 0\n",
    "        else:\n",
    "            stop += 1\n",
    "        if stop == 3000:\n",
    "            break;\n",
    "    return max_mcc, max_threshold, max_predictions.astype(int)\n",
    "\n",
    "    \n",
    "def print_save_single_roc_threshold(true_values, predictions, title, fig_name):\n",
    "    fpr, tpr, thresholds = roc_curve(true_values, predictions)\n",
    "    prediction_auc = auc(fpr, tpr)\n",
    "    \n",
    "    mcc_max, threshold, predictions = find_max_mcc_threshold(true_values, predictions, thresholds)\n",
    "    acc = accuracy_score(true_values, predictions)\n",
    "    f1 = f1_score(true_values, predictions)\n",
    "    th_index = thresholds.tolist().index(threshold)\n",
    "\n",
    "    title_font = { 'size':'17', 'color':'black', 'weight':'normal', 'verticalalignment':'bottom'}\n",
    "    axis_font = {'size':'15'}\n",
    "    cb_font = {'size':'15', 'horizontalalignment':'left'}\n",
    "    font_path = \"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\"\n",
    "    font_prop = font_manager.FontProperties(size=15)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    gs1 = gridspec.GridSpec(1, 2)\n",
    "    ax_list = [fig.add_subplot(ss) for ss in gs1]\n",
    "    ax1 =  ax_list[0]\n",
    "    ax2 =  ax_list[1]\n",
    "    lw = 2\n",
    "\n",
    "    ax1.scatter(fpr[th_index], tpr[th_index], s=75, c=\"red\", label='Optimal threshold \\n(cutoff = %0.4f)' % (threshold))\n",
    "    ax1.plot(fpr, tpr, color=\"black\", lw=lw, label='ROC curve (area = %0.4f)' % prediction_auc)\n",
    "    ax1.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle='--')\n",
    "    ax1.set_xlim([0.0, 1.0])\n",
    "    ax1.set_ylim([0.0, 1.05])\n",
    "    ax1.set_xlabel('False Positive Rate', **axis_font)\n",
    "    ax1.set_ylabel('True Positive Rate', **axis_font)\n",
    "    ax1.set_title(\"Roc analysis\",  **title_font)\n",
    "    ax1.legend(loc=\"lower right\", prop= font_prop)\n",
    "    \n",
    "    cm = confusion_matrix(true_values, predictions)\n",
    "    cm_n = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_f = [[1,0],[1,0]]\n",
    "    \n",
    "    mask1 = [[0,  1], [1, 0]]\n",
    "    mask2 = [[1,  0], [0, 1]]\n",
    "    cm1 = masked_array(cm_n,mask1)\n",
    "    cm2 = masked_array(cm_n,mask2)\n",
    "    cm1f = masked_array(cm_f,mask1)\n",
    "    cm2f = masked_array(cm_f,mask2)\n",
    "    \n",
    "    cmap1=plt.cm.get_cmap(\"correct\")\n",
    "    cmap2=plt.cm.get_cmap(\"wrong\")\n",
    "    \n",
    "    p2f = ax2.imshow(cm2f,interpolation='nearest',cmap=cmap2)\n",
    "    p1f = ax2.imshow(cm1f,interpolation='nearest',cmap=cmap1)\n",
    "   \n",
    "    p2 = ax2.imshow(cm2,interpolation='nearest',cmap=cmap2)\n",
    "    p1 = ax2.imshow(cm1,interpolation='nearest',cmap=cmap1)\n",
    "    \n",
    "    cb2 = plt.colorbar(p2,shrink=0.5)\n",
    "    cb2.set_clim(0, 1)\n",
    "    cb2.remove()\n",
    "    \n",
    "    cb1 = plt.colorbar(p1,shrink=0.5)\n",
    "    cb1.set_clim(0, 1)\n",
    "    cb1.remove()\n",
    "    \n",
    "    cb2 = plt.colorbar(p2f,shrink=0.5)\n",
    "    cb2.set_clim(0, cm1.sum())\n",
    "    cb2.ax.get_xaxis().labelpad = 10\n",
    "    cb2.ax.set_xlabel('False', **cb_font)\n",
    "    cb2.ax.tick_params(labelsize=15)\n",
    "\n",
    "    cb1 = plt.colorbar(p1f,shrink=0.5)\n",
    "    cb1.set_clim(0, cm1.sum())\n",
    "    cb1.ax.get_xaxis().labelpad = 10\n",
    "    cb1.ax.set_xlabel('True', **cb_font)\n",
    "    cb1.ax.tick_params(labelsize=15)\n",
    "\n",
    "    ax2.grid(False)\n",
    "\n",
    "    ax2.set_title(\"Confusion matrix\\n\\nACC: %0.3f   F1: %0.3f   MCC: %0.3f\" % (acc, f1, mcc_max), **title_font)\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax2.set_xticks(tick_marks)\n",
    "    ax2.set_yticks(tick_marks)\n",
    "    ax2.set_xticklabels(classes)\n",
    "    ax2.set_yticklabels(classes)\n",
    "    \n",
    "    thresh = 0.6\n",
    "\n",
    "    ax2.text(0, 0, \"%d\\n(%0.2f)\" % (cm[0,0], cm_n[0,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 1, \"%d\\n(%0.2f)\" % (cm[1,1], cm_n[1,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 0, \"%d\\n(%0.2f)\" % (cm[0,1], cm_n[0,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(0, 1, \"%d\\n(%0.2f)\" % (cm[1,0], cm_n[1,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "\n",
    "    ax2.set_ylabel('True label', **axis_font)\n",
    "    ax2.set_xlabel('Predicted label', **axis_font)\n",
    "    \n",
    "    for label in (ax2.get_xticklabels() + ax2.get_yticklabels() + ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "        label.set_fontsize(13)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=20)   \n",
    "    \n",
    "    plt.tight_layout(pad=1, w_pad=1, h_pad=1)\n",
    "    plt.savefig(\"%s/output/python/keras/images/%s.png\" % (main_dir, fig_name))\n",
    "    plt.show()\n",
    "    return \"%0.5f,%0.5f,%0.5f,%0.5f,%0.5f,%d,%d,%d,%d,%0.5f,%0.5f,%0.5f,%0.5f\" % (prediction_auc,acc,f1,mcc_max,threshold,cm[0,0],cm[1,1],cm[0,1],cm[1,0], cm_n[0,0],cm_n[1,1],cm_n[0,1],cm_n[1,0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data_tm = \"%s/data/%s/tmdata_%d_%d_%s_%s_%s_s_select.csv\" % (main_dir, crime_type, days, raster, crime_type, date_from, date_to)\n",
    "data_tm = pd.read_csv(dir_data_tm)\n",
    "\n",
    "data_tm = data_tm[data_tm.date > '2013-07-06']\n",
    "\n",
    "data_tm.sort_values('date', inplace=True)\n",
    "print(data_tm.shape)\n",
    "data_tm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "train_days_percent = 0.7\n",
    "validation_days_percent = 0.2\n",
    "\n",
    "ids_count = np.array((data_tm.drop_duplicates(\"id\", inplace = False)).iloc[:,0]).shape[0]\n",
    "rows = data_tm.shape[0]\n",
    "\n",
    "total_days = rows/ids_count\n",
    "\n",
    "train_rows = int(ids_count * total_days * train_days_percent)\n",
    "validation_rows = int(ids_count * total_days * validation_days_percent)\n",
    "test_rows = rows - train_rows - validation_rows\n",
    "print(\"Train rows: %d, validation rows: %d, test rows: %d, all: %d < %d\" % (train_rows, validation_rows, test_rows, (train_rows+validation_rows+test_rows), rows))\n",
    "\n",
    "\n",
    "X_train = (data_tm.iloc[0:train_rows,6:]).values\n",
    "X_validation = (data_tm.iloc[(train_rows):(train_rows+validation_rows),6:]).values\n",
    "X_test = (data_tm.iloc[(train_rows+validation_rows):,6:]).values\n",
    "\n",
    "y_train = data_tm.iloc[0:train_rows, 5].values\n",
    "y_validation = data_tm.iloc[(train_rows):(train_rows+validation_rows),5].values\n",
    "y_test = data_tm.iloc[(train_rows+validation_rows):,5].values\n",
    "\n",
    "n_train = y_train.shape[0]\n",
    "n_validation = y_validation.shape[0]\n",
    "n_test = y_test.shape[0]\n",
    "\n",
    "print(n_train, n_validation, n_test, (n_train + n_validation + n_test), rows)\n",
    "print((data_tm.iloc[0:train_rows,:]).date.min(), (data_tm.iloc[(train_rows):(train_rows+validation_rows),:]).date.min(), (data_tm.iloc[(train_rows+validation_rows):,:]).date.min())\n",
    "print(y_test[y_test > 0].sum())\n",
    "\n",
    "\n",
    "max_y = int(data_tm[\"crimecount\"].max())\n",
    "\n",
    "normalize_y = False\n",
    "\n",
    "if normalize_y:\n",
    "    y_train /= max_y\n",
    "    y_validation /= max_y\n",
    "    y_test /= max_y\n",
    "    \n",
    "normalize_x = True\n",
    "\n",
    "if normalize_x:\n",
    "    # normalize from [0, max] to [0, 1] so max + 1 clasess\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_validation = scaler.fit_transform(X_validation)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "binary = True\n",
    "\n",
    "if binary:\n",
    "    np.clip(y_train, 0, 1, out=y_train)\n",
    "    np.clip(y_validation, 0, 1, out=y_validation)\n",
    "    np.clip(y_test, 0, 1, out=y_test)\n",
    "    n_classes = 2\n",
    "    \n",
    "    max_y = 1\n",
    "    data_tm.crimecount[data_tm[\"crimecount\"] > 0] = 1\n",
    "    hist, bin_edges = np.histogram(data_tm[\"crimecount\"])\n",
    "    plt.bar(bin_edges[:-1], hist, width = 1)\n",
    "    plt.xlim(min(bin_edges), max(bin_edges))\n",
    "    plt.show()\n",
    "    print(hist)\n",
    "else:\n",
    "    n_classes = max_y + 1\n",
    "    hist, bin_edges = np.histogram(data[y])\n",
    "    plt.bar(bin_edges[:-1], hist, width = 1)\n",
    "    plt.xlim(min(bin_edges), max(bin_edges))\n",
    "    plt.show() \n",
    "    print(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape - timestep\n",
    "days = 21\n",
    "X_train = X_train.reshape(n_train, days, 1).astype('float16')\n",
    "X_validation = X_validation.reshape(n_validation, days, 1).astype('float16')\n",
    "X_test = X_test.reshape(n_test, days, 1).astype('float16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_file_dir = \"%s/output/python/model_results.csv\" % main_dir\n",
    "data_id = \"tm_data\"\n",
    "\n",
    "batch_size = int(X_train.shape[0]/(int(X_train.shape[0]/1298)*0.7))\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "def train_test_model_save_results_rnn_sf(model, model_id):\n",
    "    model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_validation, y_validation))\n",
    "    \n",
    "    save_dir_model = \"%s/output/python/keras/models/%s_%d_%s_%s_%s_d_%d_select_%s.h5\" % (main_dir, model_id, raster,crime_type, date_from, date_to, dist, data_id)\n",
    "    model.save(save_dir_model)\n",
    "\n",
    "    prediction = model.predict(X_test)\n",
    "\n",
    "    result_line = print_save_single_roc_threshold(y_test[:,1], prediction[:,1], \"\", \"roc_%s_%s_th\" % (data_id, model_id))\n",
    "    params = str(model.to_json())\n",
    "    with open(result_file_dir, 'a') as file:\n",
    "        file.write(\"%s,%s,%s,%s\\n\" % (model_id, data_id, result_line, params))\n",
    "        \n",
    "def train_test_model_save_results_rnn(model, model_id):\n",
    "    model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_validation, y_validation))\n",
    "    \n",
    "    save_dir_model = \"%s/output/python/keras/models/%s_%d_%s_%s_%s_d_%d_select_%s.h5\" % (main_dir, model_id, raster,crime_type, date_from, date_to, dist, data_id)\n",
    "    model.save(save_dir_model)\n",
    "\n",
    "    prediction = model.predict(X_test)\n",
    "\n",
    "    result_line = print_save_single_roc_threshold(y_test, prediction, \"\", \"roc_%s_%s_th\" % (data_id, model_id))\n",
    "    params = str(model.to_json())\n",
    "    with open(result_file_dir, 'a') as file:\n",
    "        file.write(\"%s,%s,%s,%s\\n\" % (model_id, data_id, result_line, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(days, 1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "train_test_model_save_results_rnn(model, 'rnn_1')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification 2\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(days, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "train_test_model_save_results_rnn(model, 'rnn_2')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification 3\n",
    "model = Sequential()\n",
    "model.add(LSTM(121, input_shape=(days, 1)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "train_test_model_save_results_rnn(model, 'rnn_3')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification 4\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(21, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(21, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(21, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(21, input_shape=(days, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "train_test_model_save_results_rnn(model, 'rnn_4')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification 5\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(21, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(21, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(21, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(21, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(21, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(21, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(21, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(21, input_shape=(days, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "train_test_model_save_results_rnn(model, 'rnn_5')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification, 6\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, input_shape=(days,1), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(days,1)))\n",
    "\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "model\n",
    "    \n",
    "train_test_model_save_results_rnn(model, 'rnn_6')\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification 7\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, input_shape=(days,1), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(days,1), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(days,1), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(days,1)))\n",
    "\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "model\n",
    "    \n",
    "train_test_model_save_results_rnn(model, 'rnn_7')\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification 8\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, input_shape=(days,1), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(days,1), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(days,1), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(days,1), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(days,1), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(days,1), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(days,1), return_sequences=True))\n",
    "model.add(LSTM(32, input_shape=(days,1)))\n",
    "\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "model\n",
    "    \n",
    "train_test_model_save_results_rnn(model, 'rnn_8')\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification 9\n",
    "model = Sequential()\n",
    "model.add(LSTM(8, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(8, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(8, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(8, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(8, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(8, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(8, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(8, input_shape=(days, 1)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "train_test_model_save_results_rnn(model, 'rnn_9')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification 10\n",
    "model = Sequential()\n",
    "model.add(LSTM(254, input_shape=(days, 1)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "train_test_model_save_results_rnn(model, 'rnn_10')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification 11\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(days, 1), return_sequences=True))\n",
    "model.add(LSTM(100, input_shape=(days, 1)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "train_test_model_save_results_rnn(model, 'rnn_11')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and the LSTM network timestep, classification 12\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(days, 1),return_sequences=True))\n",
    "model.add(LSTM(100, input_shape=(days, 1)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "train_test_model_save_results_rnn(model, 'rnn_12')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#load_dir_model = \"%s/output/python/rnn_model_%d_%s_%s_%s_d_%d.h5\" % (main_dir, raster,crime_type, date_from, date_to, dist)\n",
    "#model = load_model(load_dir_model)\n",
    "\n",
    "dir_data_tm = \"%s/data/%s/tmdata_%d_%d_%s_%s_%s.csv\" % (main_dir, crime_type, days, raster, crime_type, date_from, date_to)\n",
    "data_tm = pd.read_csv(dir_data_tm)\n",
    "print(data_tm.shape)\n",
    "data_tm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "load_dir_model = \"%s/output/python/rnn_model_%d_%s_%s_%s_d_%d_select3.h5\" % (main_dir, raster,crime_type, date_from, date_to, dist)\n",
    "model = load_model(load_dir_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.array((data_tm.drop_duplicates(\"id\", inplace = False, )).iloc[:,0])\n",
    "print(ids.shape)\n",
    "\n",
    "for i in range(2005, 2015):\n",
    "    rec_id = ids[i]\n",
    "    rectangle_history = data_tm.loc[(data_tm['id']==rec_id)]\n",
    "    data_X = np.array(rectangle_history.iloc[:,6:])\n",
    "    data_y = np.array(rectangle_history.iloc[:,5])\n",
    "\n",
    "    data_X = data_X.reshape((data_X.shape[0], data_X.shape[1], 1)).astype('float32')\n",
    "    data_y = data_y.astype('float32')\n",
    "    \n",
    "    data_X /= max_y\n",
    "    data_y /= max_y\n",
    "\n",
    "    prediction = model.predict(data_X)\n",
    "    print(prediction.mean())\n",
    "    #prediction_t = prediction.reshape(969)\n",
    "    #prediction_t[prediction_t != -0.00084887573] = 1\n",
    "    #prediction_t[prediction_t == -0.00084887573] = 0\n",
    "    #data_y[data_y > 0] = 1\n",
    "    \n",
    "    plt.clf\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(prediction)\n",
    "    plt.plot(data_y)\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
