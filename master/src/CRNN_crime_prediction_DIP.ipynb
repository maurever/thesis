{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append(\"./keras/lib/python3.4\")\n",
    "\n",
    "# Import libraries\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as col\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility\n",
    "import numpy.ma as ma\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import theano\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape, Input\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "raster = 200\n",
    "crime_type = \"E05\"\n",
    "date_from = \"2013-06-16\"\n",
    "date_to = \"2017-03-08\"\n",
    "dist = 5\n",
    "\n",
    "# insert main dir\n",
    "main_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "dir_neigh = \"%s/neighbour_arrays_%d_%s_%s_%s_x_%d_s_select.csv\" % (main_dir, raster,crime_type, date_from, date_to, dist)\n",
    "data_neigh = pd.read_csv(dir_neigh)\n",
    "\n",
    "data_neigh = data_neigh[data_neigh.date > '2013-07-06']\n",
    "\n",
    "data_neigh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "timesteps = 21\n",
    "\n",
    "train_days_percent = 0.7\n",
    "validation_days_percent = 0.2\n",
    "\n",
    "ids_count = np.array((data_neigh.drop_duplicates(\"id\", inplace = False)).iloc[:,0]).shape[0]\n",
    "rows = data_neigh.shape[0]\n",
    "\n",
    "total_days = rows/ids_count\n",
    "total_batches = int(total_days/timesteps)\n",
    "\n",
    "train_batches = int(total_batches*train_days_percent)\n",
    "validation_batches = int(total_batches*validation_days_percent)\n",
    "test_batches = total_batches - train_batches - validation_batches\n",
    "\n",
    "train_rows = ids_count * train_batches * timesteps\n",
    "validation_rows = ids_count * validation_batches * timesteps\n",
    "test_rows = ids_count * test_batches * timesteps\n",
    "print(\"Train rows: %d, validation rows: %d,  test_rows: %d, all: %d < %d\" % (train_rows, validation_rows, test_rows, (train_rows+validation_rows+test_rows), rows))\n",
    "\n",
    "data_neigh_train = data_neigh[0:train_rows]\n",
    "data_neigh_validation = data_neigh[(train_rows):(train_rows+validation_rows)]\n",
    "data_neigh_test = data_neigh[(train_rows+validation_rows):(train_rows+validation_rows+test_rows)]\n",
    "\n",
    "data_neigh_train.sort_values(['id','date'], ascending=[1,1], inplace=True)\n",
    "data_neigh_validation.sort_values(['id','date'], ascending=[1,1], inplace=True)\n",
    "data_neigh_test.sort_values(['id','date'], ascending=[1,1], inplace=True)\n",
    "\n",
    "X_train = data_neigh_train.iloc[:,:-5].values\n",
    "X_validation = data_neigh_validation.iloc[:,:-5].values\n",
    "X_test = data_neigh_test.iloc[:,:-5].values\n",
    "\n",
    "y_train = data_neigh_train.iloc[:, -1].values\n",
    "y_validation = data_neigh_validation.iloc[:,-1].values\n",
    "y_test = data_neigh_test.iloc[:,-1].values\n",
    "\n",
    "n_train = y_train.shape[0]\n",
    "n_validation = y_validation.shape[0]\n",
    "n_test = y_test.shape[0]\n",
    "\n",
    "\n",
    "n_train, n_validation, n_test, (n_train + n_validation + n_test), rows, data_neigh_train.date.min(), data_neigh_validation.date.min(), data_neigh_test.date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_y = int(data_neigh[\"crimecount\"].max())\n",
    "\n",
    "normalize_y = False\n",
    "\n",
    "if normalize_y:\n",
    "    y_train /= max_y\n",
    "    y_validation /= max_y\n",
    "    y_test /= max_y\n",
    "\n",
    "normalize_x = True\n",
    "\n",
    "if normalize_x:\n",
    "    # normalize from [0, max] to [0, 1] so max + 1 clasess\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_validation = scaler.fit_transform(X_validation)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "binary = True\n",
    "\n",
    "if binary:\n",
    "    np.clip(y_train, 0, 1, out=y_train)\n",
    "    np.clip(y_validation, 0, 1, out=y_validation)\n",
    "    np.clip(y_test, 0, 1, out=y_test)\n",
    "    n_classes = 2\n",
    "    \n",
    "    max_y = 1\n",
    "    data_neigh.crimecount[data_neigh[\"crimecount\"] > 0] = 1\n",
    "    hist, bin_edges = np.histogram(data_neigh[\"crimecount\"])\n",
    "    plt.bar(bin_edges[:-1], hist, width = 1)\n",
    "    plt.xlim(min(bin_edges), max(bin_edges))\n",
    "    plt.show()\n",
    "    print(hist)\n",
    "else:\n",
    "    n_classes = max_y + 1\n",
    "    hist, bin_edges = np.histogram(data[y])\n",
    "    plt.bar(bin_edges[:-1], hist, width = 1)\n",
    "    plt.xlim(min(bin_edges), max(bin_edges))\n",
    "    plt.show() \n",
    "    print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape, normalize and categorize data\n",
    "image_shape = 2*dist + 1\n",
    "timesteps = 21\n",
    "\n",
    "n_train_b = int(n_train/timesteps)\n",
    "n_validation_b = int(n_validation/timesteps)\n",
    "n_test_b = int(n_test/timesteps)\n",
    "\n",
    "X_train = X_train.reshape(n_train_b, timesteps, image_shape, image_shape,1).astype('float32')\n",
    "X_validation = X_validation.reshape(n_validation_b, timesteps, image_shape, image_shape,1).astype('float32')\n",
    "X_test = X_test.reshape(n_test_b, timesteps, image_shape, image_shape,1).astype('float32')\n",
    "\n",
    "np.save(\"X_train.npy\",X_train)\n",
    "np.save(\"X_validation.npy\",X_validation)\n",
    "np.save(\"X_test.npy\",X_test)\n",
    "       \n",
    "# Categorize depends on number of classes\n",
    "\n",
    "categorize = True\n",
    "if categorize:\n",
    "    y_train = to_categorical(y_train, 2)\n",
    "    y_validation = to_categorical(y_validation, 2)\n",
    "    y_test = to_categorical(y_test, 2)\n",
    "\n",
    "    y_train = y_train.reshape(n_train_b, timesteps,2)\n",
    "    y_validation = y_validation.reshape(n_validation_b, timesteps,2)\n",
    "    y_test = y_test.reshape(n_test_b, timesteps,2)\n",
    "\n",
    "    np.save(\"y_train_c.npy\",y_train)\n",
    "    np.save(\"y_validation_c.npy\",y_validation)\n",
    "    np.save(\"y_test_c.npy\",y_test)\n",
    "else:\n",
    "    y_train = y_train.reshape(n_train_b, timesteps,1)\n",
    "    y_validation = y_validation.reshape(n_validation_b, timesteps,1)\n",
    "    y_test = y_test.reshape(n_test_b, timesteps,1)\n",
    "    \n",
    "    np.save(\"y_train.npy\",y_train)\n",
    "    np.save(\"y_validation.npy\",y_validation)\n",
    "    np.save(\"y_test.npy\",y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as col\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import copy\n",
    "\n",
    "from numpy.ma import masked_array\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "startcolor = '#fff2e5'\n",
    "midcolor = '#f2a285'\n",
    "endcolor = '#c40d21'    \n",
    "cmap1 = col.LinearSegmentedColormap.from_list('own1',[startcolor,midcolor,endcolor])\n",
    "plt.cm.register_cmap(name = 'wrong', cmap=cmap1)\n",
    "\n",
    "startcolor = '#f3ffe5' \n",
    "midcolor = '#b4f185'   \n",
    "endcolor = 'darkgreen'   \n",
    "cmap2 = col.LinearSegmentedColormap.from_list('own2',[startcolor,midcolor,endcolor])\n",
    "plt.cm.register_cmap(name = 'correct', cmap=cmap2)\n",
    "\n",
    "classes=[0,1]\n",
    "\n",
    "def find_max_mcc_threshold(true_values, predictions, thresholds):\n",
    "    max_mcc = -1\n",
    "    max_threshold = thresholds[0]\n",
    "    max_predictions = predictions[:]\n",
    "    stop = 0\n",
    "    for i in range(1,thresholds.shape[0]):\n",
    "        tmp_threshold = thresholds[i]\n",
    "        tmp_predictions = copy.deepcopy(predictions)\n",
    "        tmp_predictions[tmp_predictions >= tmp_threshold] = int(1)\n",
    "        tmp_predictions[tmp_predictions < 1] = int(0)\n",
    "        tmp_mcc = matthews_corrcoef(true_values, tmp_predictions)\n",
    "        if tmp_mcc > max_mcc:\n",
    "            max_mcc = tmp_mcc\n",
    "            max_threshold = tmp_threshold\n",
    "            max_predictions = copy.deepcopy(tmp_predictions)\n",
    "            stop = 0\n",
    "        else:\n",
    "            stop += 1\n",
    "        if stop == 3000:\n",
    "            break;\n",
    "    return max_mcc, max_threshold, max_predictions.astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "def print_save_single_roc_threshold(true_values, predictions, title, fig_name):\n",
    "    fpr, tpr, thresholds = roc_curve(true_values, predictions)\n",
    "    prediction_auc = auc(fpr, tpr)\n",
    "    \n",
    "    mcc_max, threshold, predictions = find_max_mcc_threshold(true_values, predictions, thresholds)\n",
    "    acc = accuracy_score(true_values, predictions)\n",
    "    f1 = f1_score(true_values, predictions)\n",
    "    th_index = thresholds.tolist().index(threshold)\n",
    "\n",
    "    title_font = {'size':'17', 'color':'black', 'weight':'normal', 'verticalalignment':'bottom'}\n",
    "    axis_font = {'size':'15'}\n",
    "    cb_font = {'size':'15', 'horizontalalignment':'left'}\n",
    "    font_path = \"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\"\n",
    "    font_prop = font_manager.FontProperties(fname=font_path, size=15)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    gs1 = gridspec.GridSpec(1, 2)\n",
    "    ax_list = [fig.add_subplot(ss) for ss in gs1]\n",
    "    ax1 =  ax_list[0]\n",
    "    ax2 =  ax_list[1]\n",
    "    lw = 2\n",
    "\n",
    "    ax1.scatter(fpr[th_index], tpr[th_index], s=75, c=\"red\", label='Optimal threshold \\n(cutoff = %0.4f)' % (threshold))\n",
    "    ax1.plot(fpr, tpr, color=\"black\", lw=lw, label='ROC curve (area = %0.4f)' % prediction_auc)\n",
    "    ax1.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle='--')\n",
    "    ax1.set_xlim([0.0, 1.0])\n",
    "    ax1.set_ylim([0.0, 1.05])\n",
    "    ax1.set_xlabel('False Positive Rate', **axis_font)\n",
    "    ax1.set_ylabel('True Positive Rate', **axis_font)\n",
    "    ax1.set_title(\"Roc analysis\",  **title_font)\n",
    "    ax1.legend(loc=\"lower right\", prop= font_prop)\n",
    "    \n",
    "    cm = confusion_matrix(true_values, predictions)\n",
    "    cm_n = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_f = [[1,0],[1,0]]\n",
    "    \n",
    "    mask1 = [[0,  1], [1, 0]]\n",
    "    mask2 = [[1,  0], [0, 1]]\n",
    "    cm1 = masked_array(cm_n,mask1)\n",
    "    cm2 = masked_array(cm_n,mask2)\n",
    "    cm1f = masked_array(cm_f,mask1)\n",
    "    cm2f = masked_array(cm_f,mask2)\n",
    "    \n",
    "    cmap1=plt.cm.get_cmap(\"correct\")\n",
    "    cmap2=plt.cm.get_cmap(\"wrong\")\n",
    "    \n",
    "    p2f = ax2.imshow(cm2f,interpolation='nearest',cmap=cmap2)\n",
    "    p1f = ax2.imshow(cm1f,interpolation='nearest',cmap=cmap1)\n",
    "   \n",
    "    p2 = ax2.imshow(cm2,interpolation='nearest',cmap=cmap2)\n",
    "    p1 = ax2.imshow(cm1,interpolation='nearest',cmap=cmap1)\n",
    "    \n",
    "    cb2 = plt.colorbar(p2,shrink=0.5)\n",
    "    cb2.set_clim(0, 1)\n",
    "    cb2.remove()\n",
    "    \n",
    "    cb1 = plt.colorbar(p1,shrink=0.5)\n",
    "    cb1.set_clim(0, 1)\n",
    "    cb1.remove()\n",
    "    \n",
    "    cb2 = plt.colorbar(p2f,shrink=0.5)\n",
    "    cb2.set_clim(0, cm1.sum())\n",
    "    cb2.ax.get_xaxis().labelpad = 10\n",
    "    cb2.ax.set_xlabel('False', **cb_font)\n",
    "    cb2.ax.tick_params(labelsize=15)\n",
    "\n",
    "    cb1 = plt.colorbar(p1f,shrink=0.5)\n",
    "    cb1.set_clim(0, cm1.sum())\n",
    "    cb1.ax.get_xaxis().labelpad = 10\n",
    "    cb1.ax.set_xlabel('True', **cb_font)\n",
    "    cb1.ax.tick_params(labelsize=15)\n",
    "\n",
    "    ax2.grid(False)\n",
    "\n",
    "    ax2.set_title(\"Confusion matrix\\n\\nACC: %0.3f   F1: %0.3f   MCC: %0.3f\" % (acc, f1, mcc_max), **title_font)\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax2.set_xticks(tick_marks)\n",
    "    ax2.set_yticks(tick_marks)\n",
    "    ax2.set_xticklabels(classes)\n",
    "    ax2.set_yticklabels(classes)\n",
    "    \n",
    "    thresh = 0.6\n",
    "\n",
    "    ax2.text(0, 0, \"%d\\n(%0.2f)\" % (cm[0,0], cm_n[0,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 1, \"%d\\n(%0.2f)\" % (cm[1,1], cm_n[1,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 0, \"%d\\n(%0.2f)\" % (cm[0,1], cm_n[0,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(0, 1, \"%d\\n(%0.2f)\" % (cm[1,0], cm_n[1,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "\n",
    "    ax2.set_ylabel('True label', **axis_font)\n",
    "    ax2.set_xlabel('Predicted label', **axis_font)\n",
    "    \n",
    "    for label in (ax2.get_xticklabels() + ax2.get_yticklabels() + ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "        label.set_fontsize(13)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=20)   \n",
    "    \n",
    "    plt.tight_layout(pad=4, w_pad=2, h_pad=1)\n",
    "    plt.savefig(\"%s/output/python/keras/images/%s.png\" % (main_dir, fig_name))\n",
    "    #plt.show()\n",
    "    return \"%0.5f,%0.5f,%0.5f,%0.5f,%0.5f,%d,%d,%d,%d,%0.5f,%0.5f,%0.5f,%0.5f\" % (prediction_auc,acc,f1,mcc_max,threshold,cm[0,0],cm[1,1],cm[0,1],cm[1,0], cm_n[0,0],cm_n[1,1],cm_n[0,1],cm_n[1,0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train.npy\")\n",
    "X_validation = np.load(\"X_validation.npy\")\n",
    "X_test = np.load(\"X_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorize = False\n",
    "if categorize:\n",
    "    y_train = np.load(\"y_train_c.npy\")\n",
    "    y_validation = np.load(\"y_validation_c.npy\")\n",
    "    y_test = np.load(\"y_test_c.npy\")\n",
    "    y_test = y_test.reshape(y_test.shape[0]*y_test.shape[1],2)\n",
    "else:\n",
    "    y_train = np.load(\"y_train.npy\")\n",
    "    y_validation = np.load(\"y_validation.npy\")\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    y_test = y_test.reshape(y_test.shape[0]*y_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "timesteps = 21\n",
    "batch_size = timesteps\n",
    "\n",
    "result_file_dir = \"%s/output/python/model_results.csv\" % main_dir\n",
    "data_id = \"tm_neigh_data\"\n",
    "\n",
    "def train_test_model_save_results_crnn_sf(model, model_id):\n",
    "    model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_validation, y_validation))\n",
    "    \n",
    "    save_dir_model = \"%s/output/python/keras/models/%s_%s.h5\" % (main_dir, model_id, data_id)\n",
    "    model.save(save_dir_model)\n",
    "\n",
    "    prediction = model.predict(X_test)\n",
    "\n",
    "    prediction = prediction.reshape(prediction.shape[0]*prediction.shape[1],2)\n",
    "    result_line = print_save_single_roc_threshold(y_test[:,1], prediction[:,1], \"\", \"roc_%s_%s_th\" % (data_id, model_id))\n",
    "    params = str(model.to_json())\n",
    "    with open(result_file_dir, 'a') as file:\n",
    "        file.write(\"%s,%s,%s,%s\\n\" % (model_id, data_id, result_line, params))\n",
    "        \n",
    "def train_test_model_save_results_crnn(model, model_id):\n",
    "    model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_validation, y_validation))\n",
    "    \n",
    "    save_dir_model = \"%s/output/python/keras/models/%s_%s.h5\" % (main_dir, model_id, data_id)\n",
    "    model.save(save_dir_model)\n",
    "\n",
    "    prediction = model.predict(X_test)\n",
    "\n",
    "    prediction = prediction.reshape(prediction.shape[0]*prediction.shape[1])\n",
    "    result_line = print_save_single_roc_threshold(y_test, prediction, \"\", \"roc_%s_%s_th\" % (data_id, model_id))\n",
    "    params = str(model.to_json())\n",
    "    with open(result_file_dir, 'a') as file:\n",
    "        file.write(\"%s,%s,%s,%s\\n\" % (model_id, data_id, result_line, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model 1\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))\n",
    "    \n",
    "model.add(TimeDistributed(Dense(100, name=\"first_dense\")))\n",
    "        \n",
    "model.add(LSTM(50, return_sequences=True, name=\"lstm_layer\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 2\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))\n",
    "    \n",
    "model.add(TimeDistributed(Dense(100, name=\"first_dense\")))\n",
    "        \n",
    "model.add(LSTM(50, return_sequences=True, name=\"lstm_layer\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 3\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))\n",
    "                \n",
    "                \n",
    "model.add(TimeDistributed(Dense(100, name=\"first_dense\")))\n",
    "        \n",
    "model.add(LSTM(50, return_sequences=True, name=\"lstm_layer\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 4\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))\n",
    "                \n",
    "                \n",
    "model.add(TimeDistributed(Dense(35, name=\"first_dense\")))\n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_4')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 5\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))\n",
    "                \n",
    "                \n",
    "model.add(TimeDistributed(Dense(35, name=\"first_dense\")))\n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_5')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 6\n",
    "# number of convolutional filters\n",
    "n_filters = 16\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))                \n",
    "                \n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer1\"));\n",
    "         \n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_6')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 7\n",
    "# number of convolutional filters\n",
    "n_filters = 16\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))                \n",
    "                \n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer1\"));\n",
    "         \n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_7')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 8\n",
    "# number of convolutional filters\n",
    "n_filters = 8\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))                \n",
    "                \n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer1\"));\n",
    "         \n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_8')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 9\n",
    "# number of convolutional filters\n",
    "n_filters = 8\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))                \n",
    "                \n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer1\"));\n",
    "         \n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_9')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 10\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))\n",
    "                \n",
    "                \n",
    "model.add(TimeDistributed(Dense(35, name=\"first_dense\")))\n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer\"));\n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer2\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_10')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 11\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))\n",
    "                \n",
    "                \n",
    "model.add(TimeDistributed(Dense(35, name=\"first_dense\")))\n",
    "        \n",
    "model.add(LSTM(21, return_sequences=True, name=\"lstm_layer\"));\n",
    "model.add(LSTM(21, return_sequences=True, name=\"lstm_layer2\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_11')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 12\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))\n",
    "                \n",
    "                \n",
    "model.add(TimeDistributed(Dense(35, name=\"first_dense\")))\n",
    "        \n",
    "model.add(LSTM(21, return_sequences=True, name=\"lstm_layer\"));\n",
    "model.add(LSTM(21, return_sequences=True, name=\"lstm_layer2\"));\n",
    "model.add(LSTM(21, return_sequences=True, name=\"lstm_layer3\"));\n",
    "model.add(LSTM(21, return_sequences=True, name=\"lstm_layer4\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_12')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 8\n",
    "# number of convolutional filters\n",
    "n_filters = 8\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))                \n",
    "                \n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer1\"));\n",
    "         \n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_13')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 8\n",
    "# number of convolutional filters\n",
    "n_filters = 8\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))                \n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer1\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "         \n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_14')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 15\n",
    "# number of convolutional filters\n",
    "n_filters = 8\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))                \n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer1\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "         \n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_15')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 16\n",
    "# number of convolutional filters\n",
    "n_filters = 16\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))                \n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer1\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "         \n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_16')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 17\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))                \n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer1\"));\n",
    "\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "         \n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_17')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 18\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model=Sequential();      \n",
    "\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv), padding='same'), input_shape=X_train.shape[1:]))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(Conv2D(n_filters, (n_conv, n_conv))))\n",
    "model.add(TimeDistributed(Activation('relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(n_pool, n_pool))))\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512)))        \n",
    "\n",
    "model.add(TimeDistributed(Dense(100)))\n",
    "        \n",
    "model.add(LSTM(100, return_sequences=True, name=\"lstm_layer1\"));\n",
    "\n",
    "model.add(TimeDistributed(Dropout(0.15)))\n",
    "         \n",
    "model.add(TimeDistributed(Dense(1), name=\"time_distr_dense_one\"))\n",
    "model.add(TimeDistributed(Activation('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "train_test_model_save_results_crnn(model, 'crnn_18')\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
