{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as col\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)  \n",
    "from numpy.ma import masked_array\n",
    "\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import theano\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape, Input\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "raster = 200\n",
    "crime_type = \"E05\"\n",
    "date_from = \"2013-06-16\"\n",
    "date_to = \"2017-03-08\"\n",
    "dist = 5\n",
    "main_dir = \"/home/mori/Documents/4_semestr/DIP\"\n",
    "main_dir = \"/home/mori/DIP\"\n",
    "\n",
    "startcolor = '#fff2e5'\n",
    "midcolor = '#f2a285'\n",
    "endcolor = '#c40d21'    \n",
    "cmap1 = col.LinearSegmentedColormap.from_list('own1',[startcolor,midcolor,endcolor])\n",
    "plt.cm.register_cmap(name = 'wrong', cmap=cmap1)\n",
    "\n",
    "startcolor = '#f3ffe5' \n",
    "midcolor = '#b4f185'   \n",
    "endcolor = 'darkgreen'   \n",
    "cmap2 = col.LinearSegmentedColormap.from_list('own2',[startcolor,midcolor,endcolor])\n",
    "plt.cm.register_cmap(name = 'correct', cmap=cmap2)\n",
    "\n",
    "classes=[0,1]\n",
    "\n",
    "def find_max_mcc_threshold(true_values, predictions, thresholds):\n",
    "    max_mcc = -1\n",
    "    max_threshold = thresholds[0]\n",
    "    max_predictions = predictions[:]\n",
    "    stop = 0\n",
    "    for i in range(1,thresholds.shape[0]):\n",
    "        tmp_threshold = thresholds[i]\n",
    "        tmp_predictions = copy.deepcopy(predictions)\n",
    "        tmp_predictions[tmp_predictions >= tmp_threshold] = int(1)\n",
    "        tmp_predictions[tmp_predictions < 1] = int(0)\n",
    "        tmp_mcc = matthews_corrcoef(true_values, tmp_predictions)\n",
    "        if tmp_mcc > max_mcc:\n",
    "            max_mcc = tmp_mcc\n",
    "            max_threshold = tmp_threshold\n",
    "            max_predictions = copy.deepcopy(tmp_predictions)\n",
    "            stop = 0\n",
    "        else:\n",
    "            stop += 1\n",
    "        if stop == 5000:\n",
    "            break;\n",
    "    return max_mcc, max_threshold, max_predictions.astype(int)\n",
    "\n",
    "    \n",
    "def print_save_single_roc_threshold(true_values, predictions, title, fig_name):\n",
    "    fpr, tpr, thresholds = roc_curve(true_values, predictions)\n",
    "    prediction_auc = auc(fpr, tpr)\n",
    "    \n",
    "    mcc_max, threshold, predictions = find_max_mcc_threshold(true_values, predictions, thresholds)\n",
    "    acc = accuracy_score(true_values, predictions)\n",
    "    f1 = f1_score(true_values, predictions)\n",
    "    th_index = thresholds.tolist().index(threshold)\n",
    "\n",
    "    title_font = { 'size':'17', 'color':'black', 'weight':'normal', 'verticalalignment':'bottom'}\n",
    "    axis_font = {'size':'15'}\n",
    "    cb_font = {'size':'15', 'horizontalalignment':'left'}\n",
    "    font_path = \"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\"\n",
    "    font_prop = font_manager.FontProperties(size=15)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    gs1 = gridspec.GridSpec(1, 2)\n",
    "    ax_list = [fig.add_subplot(ss) for ss in gs1]\n",
    "    ax1 =  ax_list[0]\n",
    "    ax2 =  ax_list[1]\n",
    "    lw = 2\n",
    "\n",
    "    ax1.scatter(fpr[th_index], tpr[th_index], s=75, c=\"red\", label='Optimal threshold \\n(cutoff = %0.4f)' % (threshold))\n",
    "    ax1.plot(fpr, tpr, color=\"black\", lw=lw, label='ROC curve (area = %0.4f)' % prediction_auc)\n",
    "    ax1.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle='--')\n",
    "    ax1.set_xlim([0.0, 1.0])\n",
    "    ax1.set_ylim([0.0, 1.05])\n",
    "    ax1.set_xlabel('False Positive Rate', **axis_font)\n",
    "    ax1.set_ylabel('True Positive Rate', **axis_font)\n",
    "    ax1.set_title(\"Roc analysis\",  **title_font)\n",
    "    ax1.legend(loc=\"lower right\", prop= font_prop)\n",
    "    \n",
    "    cm = confusion_matrix(true_values, predictions)\n",
    "    cm_n = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_f = [[1,0],[1,0]]\n",
    "    \n",
    "    mask1 = [[0,  1], [1, 0]]\n",
    "    mask2 = [[1,  0], [0, 1]]\n",
    "    cm1 = masked_array(cm_n,mask1)\n",
    "    cm2 = masked_array(cm_n,mask2)\n",
    "    cm1f = masked_array(cm_f,mask1)\n",
    "    cm2f = masked_array(cm_f,mask2)\n",
    "    \n",
    "    cmap1=plt.cm.get_cmap(\"correct\")\n",
    "    cmap2=plt.cm.get_cmap(\"wrong\")\n",
    "    \n",
    "    p2f = ax2.imshow(cm2f,interpolation='nearest',cmap=cmap2)\n",
    "    p1f = ax2.imshow(cm1f,interpolation='nearest',cmap=cmap1)\n",
    "   \n",
    "    p2 = ax2.imshow(cm2,interpolation='nearest',cmap=cmap2)\n",
    "    p1 = ax2.imshow(cm1,interpolation='nearest',cmap=cmap1)\n",
    "    \n",
    "    cb2 = plt.colorbar(p2,shrink=0.5)\n",
    "    cb2.set_clim(0, 1)\n",
    "    cb2.remove()\n",
    "    \n",
    "    cb1 = plt.colorbar(p1,shrink=0.5)\n",
    "    cb1.set_clim(0, 1)\n",
    "    cb1.remove()\n",
    "    \n",
    "    cb2 = plt.colorbar(p2f,shrink=0.5)\n",
    "    cb2.set_clim(0, cm1.sum())\n",
    "    cb2.ax.get_xaxis().labelpad = 10\n",
    "    cb2.ax.set_xlabel('False', **cb_font)\n",
    "    cb2.ax.tick_params(labelsize=15)\n",
    "\n",
    "    cb1 = plt.colorbar(p1f,shrink=0.5)\n",
    "    cb1.set_clim(0, cm1.sum())\n",
    "    cb1.ax.get_xaxis().labelpad = 10\n",
    "    cb1.ax.set_xlabel('True', **cb_font)\n",
    "    cb1.ax.tick_params(labelsize=15)\n",
    "\n",
    "    ax2.grid(False)\n",
    "\n",
    "    ax2.set_title(\"Confusion matrix\\n\\nACC: %0.3f   F1: %0.3f   MCC: %0.3f\" % (acc, f1, mcc_max), **title_font)\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax2.set_xticks(tick_marks)\n",
    "    ax2.set_yticks(tick_marks)\n",
    "    ax2.set_xticklabels(classes)\n",
    "    ax2.set_yticklabels(classes)\n",
    "    \n",
    "    thresh = 0.6\n",
    "\n",
    "    ax2.text(0, 0, \"%d\\n(%0.2f)\" % (cm[0,0], cm_n[0,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 1, \"%d\\n(%0.2f)\" % (cm[1,1], cm_n[1,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 0, \"%d\\n(%0.2f)\" % (cm[0,1], cm_n[0,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(0, 1, \"%d\\n(%0.2f)\" % (cm[1,0], cm_n[1,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "\n",
    "    ax2.set_ylabel('True label', **axis_font)\n",
    "    ax2.set_xlabel('Predicted label', **axis_font)\n",
    "    \n",
    "    for label in (ax2.get_xticklabels() + ax2.get_yticklabels() + ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "        label.set_fontsize(13)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=20)   \n",
    "    \n",
    "    plt.tight_layout(pad=1, w_pad=1, h_pad=1)\n",
    "    plt.savefig(\"%s/output/python/keras/images/%s.png\" % (main_dir, fig_name))\n",
    "    plt.show()\n",
    "    return \"%0.5f,%0.5f,%0.5f,%0.5f,%0.5f,%d,%d,%d,%d,%0.5f,%0.5f,%0.5f,%0.5f\" % (prediction_auc,acc,f1,mcc_max,threshold,cm[0,0],cm[1,1],cm[0,1],cm[1,0], cm_n[0,0],cm_n[1,1],cm_n[0,1],cm_n[1,0])\n",
    "    \n",
    "\n",
    "# Load data\n",
    "dir_neigh = \"%s/output/python/neighbour_arrays_%d_%s_%s_%s_x_%d_s_select.csv\" % (main_dir, raster,crime_type, date_from, date_to, dist)\n",
    "data_neigh = pd.read_csv(dir_neigh)\n",
    "\n",
    "data_neigh = data_neigh[data_neigh.date > '2013-07-06']\n",
    "\n",
    "data_neigh.sort_values(\"date\", inplace=True)\n",
    "print(data_neigh.date.min(), data_neigh.date.max())\n",
    "data_neigh.head()    \n",
    "\n",
    "\n",
    "\n",
    "# Split data\n",
    "\n",
    "train_days_percent = 0.7\n",
    "validation_days_percent = 0.2\n",
    "\n",
    "ids_count = np.array((data_neigh.drop_duplicates(\"id\", inplace = False)).iloc[:,0]).shape[0]\n",
    "rows = data_neigh.shape[0]\n",
    "\n",
    "total_days = rows/ids_count\n",
    "\n",
    "train_rows = int(ids_count * total_days * train_days_percent)\n",
    "validation_rows = int(ids_count * total_days * validation_days_percent)\n",
    "test_rows = rows - train_rows - validation_rows\n",
    "print(\"Train rows: %d, validation rows: %d, test rows: %d, all: %d < %d\" % (train_rows, validation_rows, test_rows, (train_rows+validation_rows+test_rows), rows))\n",
    "\n",
    "X_train = data_neigh.iloc[0:train_rows,:-5].values\n",
    "X_validation = data_neigh.iloc[(train_rows):(train_rows+validation_rows),:-5].values\n",
    "X_test = data_neigh.iloc[(train_rows+validation_rows):,:-5].values\n",
    "\n",
    "y_train = data_neigh.iloc[0:train_rows, -1].values\n",
    "y_validation = data_neigh.iloc[(train_rows):(train_rows+validation_rows),-1].values\n",
    "y_test = data_neigh.iloc[(train_rows+validation_rows):,-1].values\n",
    "\n",
    "n_train = y_train.shape[0]\n",
    "n_validation = y_validation.shape[0]\n",
    "n_test = y_test.shape[0]\n",
    "\n",
    "print(n_train, n_validation, n_test, (n_train + n_validation + n_test), rows)\n",
    "print((data_neigh.iloc[0:train_rows,:]).date.min(), (data_neigh.iloc[(train_rows):(train_rows+validation_rows),:]).date.min(), (data_neigh.iloc[(train_rows+validation_rows):,:]).date.min())\n",
    "print(y_test[y_test > 0].sum())\n",
    "\n",
    "max_y = int(data_neigh[\"crimecount\"].max())\n",
    "\n",
    "normalize_y = False\n",
    "\n",
    "if normalize_y:\n",
    "    y_train /= max_y\n",
    "    y_validation /= max_y\n",
    "    y_test /= max_y\n",
    "\n",
    "binary = True\n",
    "\n",
    "if binary:\n",
    "    np.clip(y_train, 0, 1, out=y_train)\n",
    "    np.clip(y_validation, 0, 1, out=y_validation)\n",
    "    np.clip(y_test, 0, 1, out=y_test)\n",
    "    n_classes = 2\n",
    "    \n",
    "    max_y = 1\n",
    "    data_neigh.crimecount[data_neigh[\"crimecount\"] > 0] = 1\n",
    "    hist, bin_edges = np.histogram(data_neigh[\"crimecount\"])\n",
    "    plt.bar(bin_edges[:-1], hist, width = 1)\n",
    "    plt.xlim(min(bin_edges), max(bin_edges))\n",
    "    plt.show()\n",
    "    print(hist)\n",
    "else:\n",
    "    n_classes = max_y + 1\n",
    "    hist, bin_edges = np.histogram(data[y])\n",
    "    plt.bar(bin_edges[:-1], hist, width = 1)\n",
    "    plt.xlim(min(bin_edges), max(bin_edges))\n",
    "    plt.show() \n",
    "    print(hist)\n",
    "\n",
    "# Reshape, normalize and categorize data\n",
    "image_shape = 2*dist + 1\n",
    "X_train = X_train.reshape(n_train, 1, image_shape, image_shape).astype('float32')\n",
    "X_validation = X_validation.reshape(n_validation, 1, image_shape, image_shape).astype('float32')\n",
    "X_test = X_test.reshape(n_test, 1, image_shape, image_shape).astype('float32')\n",
    "\n",
    "\n",
    "# How many examples to look at during each training iteration\n",
    "batch_size = int(total_days)\n",
    "\n",
    "# How many times to run through the full set of examples\n",
    "epochs = 1\n",
    "\n",
    "result_file_dir = \"%s/output/python/model_results.csv\" % main_dir\n",
    "data_id = \"neigh_data\"\n",
    "\n",
    "def train_test_model_save_results_cnn(model, model_id):\n",
    "    model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_validation, y_validation))\n",
    "    \n",
    "    save_dir_model = \"%s/output/python/keras/models/%s_%s.h5\" % (main_dir, model_id, data_id)\n",
    "    model.save(save_dir_model)\n",
    "\n",
    "    prediction = model.predict(X_test)\n",
    "    result_line = print_save_single_roc_threshold(y_test, prediction, \"\", \"cnn_roc_%s_%s_th\" %(model_id, data_id))\n",
    "    params = str(model.to_json()) \n",
    "    with open(result_file_dir, 'a') as file:\n",
    "        file.write(\"%s,%s,%s,%s\\n\" % (model_id, data_id, result_line, params))\n",
    "\n",
    "# Model 1\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 8\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_1\")\n",
    "print(\"1 Done.\")\n",
    "\n",
    "# Model 2\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 16\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_2\")\n",
    "print(\"2 Done.\")\n",
    "\n",
    "# Model 3\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_3\")\n",
    "print(\"3 Done.\")\n",
    "\n",
    "# Model 4\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 8\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_4\")\n",
    "print(\"4 Done.\")\n",
    "\n",
    "\n",
    "# Model 5\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 16\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_5\")\n",
    "print(\"5 Done.\")\n",
    "\n",
    "\n",
    "# Model 6\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_6\")\n",
    "print(\"6 Done.\")\n",
    "\n",
    "# Model 7\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 64\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_7\")\n",
    "print(\"7 Done.\")\n",
    "\n",
    "# Model 8\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 128\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_8\")\n",
    "print(\"8 Done.\")\n",
    "\n",
    "# Model 9\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 256\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_9\")\n",
    "print(\"9 Done.\")\n",
    "\n",
    "# Model 10\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 8\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_10\")\n",
    "print(\"10 Done.\")\n",
    "\n",
    "# Model 11\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 16\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_11\")\n",
    "print(\"11 Done.\")\n",
    "\n",
    "# Model 12\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_12\")\n",
    "print(\"12 Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 13\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='valid',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_13\")\n",
    "print(\"13 Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 14\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "\n",
    "# convolution filter size\n",
    "n_conv = 2\n",
    "\n",
    "# pooling window size\n",
    "n_pool = 2\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "        border_mode='same',\n",
    "        input_shape=(1, image_shape, image_shape)\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, n_conv, n_conv))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "train_test_model_save_results_cnn(model, \"cnn_14\")\n",
    "print(\"14 Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
