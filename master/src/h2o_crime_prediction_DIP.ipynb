{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>Crime prediction</h1>\n",
    "\n",
    "<h3>Data mergin, clearing and completing - R script (main.R)</h3>\n",
    "1. from date to date +/- days in past you want to extract information\n",
    "2. from rectangle to rectangle (better from latitude/longtitude to latitude/longtitude) +/- extra area to extract information at border\n",
    "\n",
    "<h3>Generate numpy arrays - IPython notebook (preprocess_neighbour_arrays.ipynb)</h3>\n",
    "1. Go throught rectangles\n",
    "2. Go througth dates\n",
    "3. Select surrounding in defined distance the day before -> 2D array\n",
    "4. Save array and result into result array -> 3D array\n",
    "\n",
    "<h3>Extract features using CNN - IPython notebook (crime_feature_extraction_CNN.ipynb)</h3>\n",
    "1. Train convolution net\n",
    "2. Remove last layer\n",
    "3. Generate feature vector for all data\n",
    "\n",
    "<h3>Extract features using timeseries and RNN - IPython notebook (crime_feature_extraction_RNN.ipynb) </h3>\n",
    "1. Train RNN net\n",
    "2. Generate feature vector for all data\n",
    "\n",
    "<h3>Features selection - IPython notebook (crime_feature_selection.ipynb)</h3>\n",
    "1. Load and select data\n",
    "2. Join together with tm_data_complete datasest\n",
    "3. Train tree model\n",
    "4. Visualize feature importance\n",
    "5. Select the most important features\n",
    "6. Save data\n",
    "\n",
    "<h2><font color='green'>Crime prediction - IPython notebook (crime_prediction.ipynb)</font></h2>\n",
    "<b>\n",
    "1. Create models (Deep learning, Random Forest, Gradient Boosting Machines)\n",
    "2. Train models\n",
    "3. Test models\n",
    "4. Colect and visualize the results\n",
    "5. Do it for various features\n",
    "6. Compare all models and select best results\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.ma import masked_array\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as col\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import h2o\n",
    "\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "raster = 200\n",
    "crime_type = \"E05\"\n",
    "date_from = \"2013-06-16\"\n",
    "date_to = \"2017-03-08\"\n",
    "dist = 5\n",
    "days = 21\n",
    "main_dir = \"/home/mori/Documents/4_semestr/DIP\"\n",
    "main_dir = \"/home/elita/keras/DIP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data preprocess+timeseries+neighbours\n",
    "data_dir = \"%s/output/python/complet_tm_neigh_%d_%s_%s_%s_x_%d_s_select_pca.csv\" % (main_dir, raster,crime_type, date_from, date_to, dist)\n",
    "data = pd.read_csv(data_dir)\n",
    "data.sort_values(\"date\", inplace=True)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,22):\n",
    "    name = \"d%d\" % i\n",
    "    data[name] = data[name]/7\n",
    "\n",
    "# to binary classification\n",
    "y = 'crimecount_x'\n",
    "\n",
    "binary = True\n",
    "if binary:\n",
    "    data.crimecount_x[data[y] > 0] = 1\n",
    "\n",
    "    max_y = int(data[y].max())\n",
    "    hist, bin_edges = np.histogram(data[y])\n",
    "    plt.bar(bin_edges[:-1], hist, width = 1)\n",
    "    plt.xlim(min(bin_edges), max(bin_edges))\n",
    "    plt.show()   \n",
    "\n",
    "    print([hist[0], hist[9]])\n",
    "else:\n",
    "    max_y = int(data[y].max())\n",
    "\n",
    "    hist, bin_edges = np.histogram(data[y])\n",
    "    plt.bar(bin_edges[:-1], hist, width = 1)\n",
    "    plt.xlim(min(bin_edges), max(bin_edges))\n",
    "    plt.show()   \n",
    "    print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "train_days_percent = 0.7\n",
    "validation_days_percent = 0.2\n",
    "\n",
    "ids_count = np.array((data.drop_duplicates(\"id\", inplace = False)).iloc[:,0]).shape[0]\n",
    "rows = data.shape[0]\n",
    "\n",
    "total_days = rows/ids_count\n",
    "\n",
    "train_rows = int(ids_count * total_days * train_days_percent)\n",
    "validation_rows = int(ids_count * total_days * validation_days_percent)\n",
    "test_rows = rows - train_rows - validation_rows\n",
    "\n",
    "print(\"Train rows: %d, validation rows: %d, test_rows: %d, all: %d < %d\" % (train_rows, validation_rows, test_rows, (train_rows+validation_rows+test_rows), rows))\n",
    "\n",
    "train = data.iloc[0:train_rows,]\n",
    "validation = data.iloc[(train_rows):(train_rows+validation_rows),]\n",
    "test = data.iloc[(train_rows+validation_rows):,]\n",
    "\n",
    "n_train, _ = train.shape\n",
    "n_validation, _ = validation.shape\n",
    "n_test, _ = test.shape\n",
    "\n",
    "\n",
    "n_train, n_validation, n_test, (n_train + n_validation + n_test), rows, max_y, train.date.min(), validation.date.min(), test.date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ind = np.arange(2)  \n",
    "width = 0.25    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "hist, _ = np.histogram(train[y])\n",
    "train_c = (hist[0], hist[-1])\n",
    "rects1 = ax.bar(ind, train_c, width)\n",
    "\n",
    "hist, _ = np.histogram(validation[y])\n",
    "validation_c = (hist[0], hist[-1])\n",
    "rects2 = ax.bar(ind + width, validation_c, width)\n",
    "\n",
    "hist, _ = np.histogram(test[y])\n",
    "test_c = (hist[0], hist[-1])\n",
    "rects3 = ax.bar(ind + 2*width, test_c, width)\n",
    "\n",
    "axis_font = {'size':'20'}\n",
    "font_prop = font_manager.FontProperties(size=16)\n",
    "\n",
    "\n",
    "ax.set_xticks(ind + width)\n",
    "ax.set_xticklabels(('0', '1'))\n",
    "ax.set_ylim(0,1300000)\n",
    "ax.set_ylabel('Count', **axis_font)\n",
    "ax.set_xlabel('Class', **axis_font)\n",
    "\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(16)\n",
    "\n",
    "ax.legend((rects1[0], rects2[0], rects3[0]), ('Training', 'Validation', 'Test'), prop= font_prop)\n",
    "\n",
    "def autolabel(rects, ax, decimal = False):\n",
    "    (y_bottom, y_top) = ax.get_ylim()\n",
    "    y_height = y_top - y_bottom\n",
    "\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        label_position = height + (y_height * 0.01)\n",
    "\n",
    "        if decimal:\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., label_position, '%0.3f' % height, ha='center', va='bottom', size = 16)\n",
    "        else:\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., label_position, '%d' % int(height), ha='center', va='bottom', size = 16)\n",
    "            \n",
    "\n",
    "autolabel(rects1, ax)\n",
    "autolabel(rects2, ax)\n",
    "autolabel(rects3, ax)\n",
    "\n",
    "plt.savefig(\"%s/images/data_spliting_a.png\" % main_dir)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "hist, _ = np.histogram(train[y])\n",
    "train_c = np.array((hist[0], hist[-1]))\n",
    "train_cn = (train_c/train_c.sum()).tolist()\n",
    "rects1 = ax.bar(ind, train_cn, width)\n",
    "\n",
    "hist, _ = np.histogram(validation[y])\n",
    "validation_c = np.array((hist[0], hist[-1]))\n",
    "validation_cn = (validation_c/validation_c.sum()).tolist()\n",
    "rects2 = ax.bar(ind+width, validation_cn, width)\n",
    "\n",
    "hist, _ = np.histogram(test[y])\n",
    "test_c = np.array((hist[0], hist[-1]))\n",
    "test_cn = (test_c/test_c.sum()).tolist()\n",
    "rects3 = ax.bar(ind+2*width, test_cn, width)\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Normalised count', **axis_font)\n",
    "ax.set_xlabel('Class', **axis_font)\n",
    "ax.set_xticks(ind + width)\n",
    "ax.set_xticklabels(('0', '1'))\n",
    "ax.set_ylim(0,1.1)\n",
    "\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(16)\n",
    "        \n",
    "ax.legend((rects1[0], rects2[0], rects3[0]), ('Training', 'Validation', 'Test'), prop= font_prop)\n",
    "\n",
    "autolabel(rects1, ax, True)\n",
    "autolabel(rects2, ax, True)\n",
    "autolabel(rects3, ax, True)\n",
    "\n",
    "plt.savefig(\"%s/images/data_spliting_n.png\" % main_dir)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "header = \",\".join(data.columns.values)\n",
    "np.savetxt(\"%s/output/python/train.csv\"%main_dir, train, fmt='%s', header=header, delimiter=',')\n",
    "np.savetxt(\"%s/output/python/validation.csv\"%main_dir, validation, fmt='%s', header=header, delimiter=',')\n",
    "np.savetxt(\"%s/output/python/test.csv\"%main_dir, test, fmt='%s', header=header,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train[y].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "header = \",\".join(data.columns.values[182:])\n",
    "np.savetxt(\"%s/output/python/train_pca_only.csv\"%main_dir, train.iloc[:,182:], fmt='%s', header=header, delimiter=';')\n",
    "np.savetxt(\"%s/output/python/validation_pca_only.csv\"%main_dir, validation.iloc[:,182:], fmt='%s', header=header, delimiter=';')\n",
    "np.savetxt(\"%s/output/python/test_pca_only.csv\"%main_dir, test.iloc[:,182:], fmt='%s', header=header,delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.iloc[:,183:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#h2o.cluster().shutdown()\n",
    "h2o.init(min_mem_size=\"10G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "column_types = [\"enum\", \"numeric\", \"numeric\", \"numeric\",\n",
    "               \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "               \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "               \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",\n",
    "                \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\",         \n",
    "               ]\n",
    "\n",
    "column_names = [\"crimecount\", \"PCA_0\",\"PCA_1\",\n",
    "                \"PCA_2\",\"PCA_3\",\"PCA_4\", \"PCA_5\",\"PCA_6\",\"PCA_7\",\"PCA_8\",\"PCA_9\",\"PCA_10\",\"PCA_11\",\"PCA_12\",\"PCA_13\",\"PCA_14\",\n",
    "\"PCA_15\",\"PCA_16\",\"PCA_17\",\"PCA_18\",\"PCA_19\",\"PCA_20\",\"PCA_21\",\"PCA_22\",\"PCA_23\",\"PCA_24\",\n",
    "\"PCA_25\",\"PCA_26\",\"PCA_27\",\"PCA_28\",\"PCA_29\",\"PCA_30\",\"PCA_31\",\"PCA_32\",\"PCA_33\",\"PCA_34\",\n",
    "\"PCA_35\",\"PCA_36\",\"PCA_37\",\"PCA_38\",\"PCA_39\",\"PCA_40\",\"PCA_41\",\"PCA_42\",\"PCA_43\",\"PCA_44\",\n",
    "\"PCA_45\",\"PCA_46\",\"PCA_47\",\"PCA_48\",\"PCA_49\",\"PCA_50\",\"PCA_51\",\"PCA_52\",\"PCA_53\",\"PCA_54\",\n",
    "\"PCA_55\",\"PCA_56\",\"PCA_57\",\"PCA_58\",\"PCA_59\",\"PCA_60\",\"PCA_61\",\"PCA_62\",\"PCA_63\",\"PCA_64\",\n",
    "\"PCA_65\",\"PCA_66\",\"PCA_67\",\"PCA_68\",\"PCA_69\",\"PCA_70\",\"PCA_71\",\"PCA_72\",\"PCA_73\",\"PCA_74\",\n",
    "\"PCA_75\",\"PCA_76\",\"PCA_77\",\"PCA_78\",\"PCA_79\",\"PCA_80\",\"PCA_81\",\"PCA_82\",\"PCA_83\",\"PCA_84\",\n",
    "\"PCA_85\",\"PCA_86\",\"PCA_87\",\"PCA_88\",\"PCA_89\",\"PCA_90\",\"PCA_91\",\"PCA_92\",\"PCA_93\",\"PCA_94\",\n",
    "\"PCA_95\",\"PCA_96\",\"PCA_97\",\"PCA_98\",\"PCA_99\",\"PCA_100\",\"PCA_101\",\"PCA_102\",\"PCA_103\",\"PCA_104\",\n",
    "\"PCA_105\",\"PCA_106\",\"PCA_107\",\"PCA_108\",\"PCA_109\",\"PCA_110\",\"PCA_111\",\"PCA_112\",\"PCA_113\",\"PCA_114\",\n",
    "\"PCA_115\",\"PCA_116\",\"PCA_117\",\"PCA_118\",\"PCA_119\",\"PCA_120\",\"PCA_121\",\"PCA_122\",\"PCA_123\",\"PCA_124\",\n",
    "\"PCA_125\",\"PCA_126\",\"PCA_127\",\"PCA_128\",\"PCA_129\",\"PCA_130\",\"PCA_131\",\"PCA_132\",\"PCA_133\",\"PCA_134\",\n",
    "\"PCA_135\",\"PCA_136\",\"PCA_137\",\"PCA_138\",\"PCA_139\",\"PCA_140\",\"PCA_141\",\"PCA_142\",\"PCA_143\",\"PCA_144\",\n",
    "\"PCA_145\",\"PCA_146\",\"PCA_147\",\"PCA_148\",\"PCA_149\",\"PCA_150\",\"PCA_151\",\"PCA_152\",\"PCA_153\",\"PCA_154\",\n",
    "\"PCA_155\",\"PCA_156\",\"PCA_157\",\"PCA_158\",\"PCA_159\",\"PCA_160\",\"PCA_161\",\"PCA_162\"\n",
    "]\n",
    "\n",
    "trainH2o = h2o.upload_file(path=\"%s/output/python/train_pca_only.csv\"%main_dir, destination_frame=\"train_data\", header=1, col_names = column_names, col_types = column_types)\n",
    "validationH2o = h2o.import_file(path=\"%s/output/python/validation_pca_only.csv\"%main_dir, destination_frame=\"validation_data\", header=1, col_names = column_names, col_types = column_types)\n",
    "testH2o = h2o.import_file(path=\"%s/output/python/test_pca_only.csv\"%main_dir, destination_frame=\"test_data\", header=1, col_names = column_names, col_types = column_types)\n",
    "\n",
    "#trainH2o = h2o.H2OFrame(train, column_types=column_types)\n",
    "#validationH2o = h2o.H2OFrame(validation, column_types=column_types)\n",
    "#testH2o = h2o.H2OFrame(test, column_types=column_types)\n",
    "\n",
    "#true_values = test.loc[:, \"crimecount_x\"]\n",
    "true_values = pd.read_csv(\"%s/output/python/test.csv\"%main_dir, skipinitialspace=True, usecols=[\"crimecount_x\"]).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "column_types = [\"numeric\",\"string\",\"enum\",\"enum\",\"enum\",\"enum\",\"enum\",\"enum\",\"enum\", \"enum\",\"enum\",\n",
    "                \"enum\",\"enum\",\"enum\",\"enum\",\"enum\", \"enum\",\"enum\",\"enum\",\"enum\",\n",
    "                \"enum\",\"enum\",\"enum\",\"enum\",\"numeric\",\"numeric\",\"numeric\",\"numeric\",\n",
    "                \"enum\",\"enum\",\"enum\",\"enum\",\"enum\",\"enum\",\"numeric\",\"numeric\",\n",
    "                \"numeric\",\"numeric\", \"numeric\",\"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"numeric\", \"numeric\",\n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\",\n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\",  \n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\",\n",
    "                \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \"enum\", \n",
    "                \"enum\", \"numeric\", \"numeric\", \"enum\", \"numeric\", \"numeric\", \"numeric\", \"numeric\", \"numeric\"]\n",
    "\n",
    "column_names = [\"id\",\"date\",\"d1\",\"d2\",\"d3\",\"d4\",\"d5\",\"d6\",\"d7\",\"d8\",\"d9\",\n",
    "                \"d10\",\"d11\",\"d12\",\"d13\",\"d14\",\"d15\",\"d16\",\"d17\",\"d18\",\"d19\",\n",
    "                \"d20\",\"d21\",\"praha\",\"idx200\",\"x200\",\"idy200\",\"y200\",\"Y\",\n",
    "                \"Mo\",\"W\",\"WD\",\"D\",\"MoCat\",\"lokalitarelevance\",\"vzdbcs\",\"vzdpostabanka\",\n",
    "                \"vzdprodejna\", \"vzdrestaurace\",\"datDoOdDiffDf_0\",\"datDoOdDiffDf_1\",\"datDoOdDiffDf_2\",\"datDoOdDiffDf_3\",\n",
    "                \"datDoOdDiffDf_4\",\"datDoOdDiffDf_5\",\"datDoOdDiffDf_6\",\"datDoOdDiffDf_7\",\"crimecount_x\",\n",
    "                \"stavobj_A\",\"stavobj_B\",\"stavobj_C\",\"stavobj_D\",\"stavobj_F\",\"stavobj_G\",\"datodHCat_1\",\n",
    "                \"datodHCat_2\",\"datodHCat_3\",\"datodHCat_4\",\"datodHCat_5\",\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\n",
    "                \"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\n",
    "                \"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\n",
    "                \"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\n",
    "                \"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\n",
    "                \"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\n",
    "                \"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\n",
    "                \"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"x\",\"y\",\"crimecount_y\",\"PCA_0\",\"PCA_1\",\n",
    "                \"PCA_2\",\"PCA_3\",\"PCA_4\"\n",
    "]\n",
    "\n",
    "trainH2o = h2o.upload_file(path=\"%s/output/python/train.csv\"%main_dir, destination_frame=\"train_data\", header=1, col_names = column_names, col_types = column_types)\n",
    "validationH2o = h2o.import_file(path=\"%s/output/python/validation.csv\"%main_dir, destination_frame=\"validation_data\", header=1, col_names = column_names, col_types = column_types)\n",
    "testH2o = h2o.import_file(path=\"%s/output/python/test.csv\"%main_dir, destination_frame=\"test_data\", header=1, col_names = column_names, col_types = column_types)\n",
    "\n",
    "#trainH2o = h2o.H2OFrame(train, column_types=column_types)\n",
    "#validationH2o = h2o.H2OFrame(validation, column_types=column_types)\n",
    "#testH2o = h2o.H2OFrame(test, column_types=column_types)\n",
    "\n",
    "#true_values = test.loc[:, \"crimecount_x\"]\n",
    "true_values = pd.read_csv(\"%s/output/python/test.csv\"%main_dir, skipinitialspace=True, usecols=[\"crimecount_x\"]).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "startcolor = '#fff2e5'\n",
    "midcolor = '#f2a285'\n",
    "endcolor = '#c40d21'    \n",
    "cmap1 = col.LinearSegmentedColormap.from_list('own1',[startcolor,midcolor,endcolor])\n",
    "plt.cm.register_cmap(name = 'wrong', cmap=cmap1)\n",
    "\n",
    "startcolor = '#f3ffe5' \n",
    "midcolor = '#b4f185'   \n",
    "endcolor = 'darkgreen'   \n",
    "cmap2 = col.LinearSegmentedColormap.from_list('own2',[startcolor,midcolor,endcolor])\n",
    "plt.cm.register_cmap(name = 'correct', cmap=cmap2)\n",
    "\n",
    "classes=[0,1]\n",
    "\n",
    "def print_save_single_roc(true_values, predictions, color, title, fig_name):\n",
    "    fpr, tpr, thresholds = roc_curve(true_values, predictions)\n",
    "    prediction_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color=color, lw=lw, label='ROC curve (area = %0.4f)' % prediction_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"%s/images/%s.png\" % (main_dir, fig_name))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_save_multy_roc(true_values, predictions, n, model_names, colors, title, fig_name):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    prediction_auc = dict()\n",
    "    for i in range(n):\n",
    "        fpr[i], tpr[i], _ = roc_curve(true_values, predictions[i])\n",
    "        prediction_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    title_font = {'size':'30', 'color':'black', 'weight':'normal', 'verticalalignment':'bottom'}\n",
    "    axis_font = {'size':'25'}\n",
    "    font_path = \"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\"\n",
    "    font_prop = font_manager.FontProperties(size=20)\n",
    "        \n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(16)\n",
    "        \n",
    "    lw = 2\n",
    "    for j in range(n):\n",
    "        plt.plot(fpr[j], tpr[j], color=colors[j], lw=lw, label='ROC curve of {0} model (area = {1:0.4f})'.format(model_names[j], prediction_auc[j]))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', **axis_font)\n",
    "    plt.ylabel('True Positive Rate', **axis_font)\n",
    "    plt.title(title, **title_font)\n",
    "    plt.legend(loc=\"lower right\", prop=font_prop)\n",
    "    plt.savefig(\"%s/images/%s.png\" % (main_dir, fig_name))\n",
    "    plt.show() \n",
    "    \n",
    "def print_save_multy_prc(true_values, predictions, n, model_names, colors, title, fig_name):\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(n):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(true_values, predictions[i])\n",
    "        average_precision[i] = average_precision_score(true_values, predictions[i])\n",
    "    \n",
    "    title_font = {'size':'30', 'color':'black', 'weight':'normal', 'verticalalignment':'bottom'}\n",
    "    axis_font = {'size':'25'}\n",
    "    font_path = \"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\"\n",
    "    font_prop = font_manager.FontProperties(size=20)\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(16)\n",
    "    \n",
    "    lw = 2\n",
    "    for j in range(n):\n",
    "        plt.plot(precision[j], recall[j], color=colors[j], lw=lw, label='PRC curve of {0} model (area = {1:0.4f})'.format(model_names[j], average_precision[j]))\n",
    "    \n",
    "    ratio = len(true_values[true_values == 1])/len(true_values[true_values == 0])\n",
    "    plt.plot([ratio, ratio], color='gray', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 0.5])\n",
    "    plt.ylim([0.0, 0.2])\n",
    "    plt.xlabel('Recall',  **axis_font)\n",
    "    plt.ylabel('Precision', **axis_font)\n",
    "    plt.title(title, **title_font)\n",
    "    plt.legend(loc=\"upper right\", prop=font_prop)\n",
    "    plt.savefig(\"%s/images/%s.png\" % (main_dir, fig_name))\n",
    "    plt.show()\n",
    "    \n",
    "def find_max_mcc_threshold(true_values, predictions, thresholds):\n",
    "    max_mcc = -1\n",
    "    max_threshold = thresholds[0]\n",
    "    max_predictions = predictions[:]\n",
    "    stop = 0\n",
    "    for i in range(1,thresholds.shape[0]):\n",
    "        tmp_threshold = thresholds[i]\n",
    "        tmp_predictions = copy.deepcopy(predictions)\n",
    "        tmp_predictions[tmp_predictions >= tmp_threshold] = int(1)\n",
    "        tmp_predictions[tmp_predictions < 1] = int(0)\n",
    "        tmp_mcc = matthews_corrcoef(true_values, tmp_predictions)\n",
    "        if tmp_mcc > max_mcc:\n",
    "            max_mcc = tmp_mcc\n",
    "            max_threshold = tmp_threshold\n",
    "            max_predictions = copy.deepcopy(tmp_predictions)\n",
    "            stop = 0\n",
    "        else:\n",
    "            stop += 1\n",
    "        if stop == 3000:\n",
    "            break;\n",
    "    return max_mcc, max_threshold, max_predictions.astype(int)\n",
    "\n",
    "def find_max_f1_threshold(true_values, predictions, thresholds):\n",
    "    max_f1 = -1\n",
    "    max_threshold = thresholds[0]\n",
    "    max_predictions = predictions[:]\n",
    "    stop = 0\n",
    "    for i in range(1,thresholds.shape[0]):\n",
    "        tmp_threshold = thresholds[i]\n",
    "        tmp_predictions = copy.deepcopy(predictions)\n",
    "        tmp_predictions[tmp_predictions >= tmp_threshold] = int(1)\n",
    "        tmp_predictions[tmp_predictions < 1] = int(0)\n",
    "        tmp_f1 = f1_score(true_values, tmp_predictions)\n",
    "        if tmp_f1 > max_f1:\n",
    "            max_f1 = tmp_f1\n",
    "            max_threshold = tmp_threshold\n",
    "            max_predictions = copy.deepcopy(tmp_predictions)\n",
    "            stop = 0\n",
    "        else:\n",
    "            stop += 1\n",
    "        #if stop == 3000:\n",
    "        #    break;\n",
    "    return max_f1, max_threshold, max_predictions.astype(int)\n",
    "\n",
    "def plot_and_save_bi_confusion_matrix(cm, fig_name, title='Confusion matrix', classes = [0,1], cmap1=plt.cm.get_cmap(\"correct\"), cmap2=plt.cm.get_cmap(\"wrong\")):\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontsize(15)\n",
    "    \n",
    "    title_font = {'size':'20', 'color':'black', 'weight':'normal', 'verticalalignment':'bottom'}\n",
    "    axis_font = {'size':'15'}\n",
    "    cb_font = {'size':'15', 'horizontalalignment':'left'}\n",
    "    font_path = \"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\"\n",
    "    font_prop = font_manager.FontProperties(size=20)\n",
    "    \n",
    "    cm_n = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_f = [[1,0],[1,0]]\n",
    "    \n",
    "    mask1 = [[0,  1], [1, 0]]\n",
    "    mask2 = [[1,  0], [0, 1]]\n",
    "    cm1 = masked_array(cm_n,mask1)\n",
    "    cm2 = masked_array(cm_n,mask2)\n",
    "    \n",
    "    cm1f = masked_array(cm_f,mask1)\n",
    "    cm2f = masked_array(cm_f,mask2)\n",
    "    \n",
    "    p2f = ax.imshow(cm2f,interpolation='nearest',cmap=cmap2)\n",
    "    p1f = ax.imshow(cm1f,interpolation='nearest',cmap=cmap1)\n",
    "    \n",
    "    p2 = ax.imshow(cm2,interpolation='nearest',cmap=cmap2)\n",
    "    p1 = ax.imshow(cm1,interpolation='nearest',cmap=cmap1)\n",
    "    \n",
    "    cb2 = plt.colorbar(p2,shrink=0.5)\n",
    "    cb2.set_clim(0, 1)\n",
    "    cb2.remove()\n",
    "    \n",
    "    cb1 = plt.colorbar(p1,shrink=0.5)\n",
    "    cb1.set_clim(0, 1)\n",
    "    cb1.remove()\n",
    "    \n",
    "    cb2 = plt.colorbar(p2f,shrink=0.5)\n",
    "    cb2.set_clim(0, 1)\n",
    "    cb2.ax.get_xaxis().labelpad = 10\n",
    "    cb2.ax.set_xlabel('False', **cb_font)\n",
    "    cb2.ax.tick_params(labelsize=15)\n",
    "    \n",
    "    \n",
    "    cb1 = plt.colorbar(p1f,shrink=0.5)\n",
    "    cb1.set_clim(0, 1)\n",
    "    cb1.ax.get_xaxis().labelpad = 10\n",
    "    cb1.ax.set_xlabel('True', **cb_font)\n",
    "    cb1.ax.tick_params(labelsize=15)\n",
    "\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.title(title, **title_font)\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = 0.6\n",
    "\n",
    "    plt.text(0, 0, \"%d\\n(%0.2f)\" % (cm[0,0], cm_n[0,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "    plt.text(1, 1, \"%d\\n(%0.2f)\" % (cm[1,1], cm_n[1,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    plt.text(1, 0, \"%d\\n(%0.2f)\" % (cm[0,1], cm_n[0,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    plt.text(0, 1, \"%d\\n(%0.2f)\" % (cm[1,0], cm_n[1,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', **axis_font)\n",
    "    plt.xlabel('Predicted label', **axis_font)    \n",
    "    plt.savefig(\"%s/output/python/h2o/images/%s.png\" % (main_dir, fig_name))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def print_save_single_roc_threshold(true_values, predictions, title, fig_name):\n",
    "    fpr, tpr, thresholds = roc_curve(true_values, predictions)\n",
    "    prediction_auc = auc(fpr, tpr)\n",
    "    \n",
    "    mcc_max, threshold, predictions = find_max_mcc_threshold(true_values, predictions, thresholds)\n",
    "    acc = accuracy_score(true_values, predictions)\n",
    "    f1 = f1_score(true_values, predictions)\n",
    "    th_index = thresholds.tolist().index(threshold)\n",
    "\n",
    "    title_font = {'size':'17', 'color':'black', 'weight':'normal', 'verticalalignment':'bottom'}\n",
    "    axis_font = {'size':'15'}\n",
    "    cb_font = {'size':'15', 'horizontalalignment':'left'}\n",
    "    font_path = \"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\"\n",
    "    font_prop = font_manager.FontProperties(size=15)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    gs1 = gridspec.GridSpec(1, 2)\n",
    "    ax_list = [fig.add_subplot(ss) for ss in gs1]\n",
    "    ax1 =  ax_list[0]\n",
    "    ax2 =  ax_list[1]\n",
    "    lw = 2\n",
    "\n",
    "    ax1.scatter(fpr[th_index], tpr[th_index], s=75, c=\"red\", label='Optimal threshold \\n(cutoff = %0.4f)' % (threshold))\n",
    "    ax1.plot(fpr, tpr, color=\"black\", lw=lw, label='ROC curve (area = %0.4f)' % prediction_auc)\n",
    "    ax1.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle='--')\n",
    "    ax1.set_xlim([0.0, 1.0])\n",
    "    ax1.set_ylim([0.0, 1.05])\n",
    "    ax1.set_xlabel('False Positive Rate', **axis_font)\n",
    "    ax1.set_ylabel('True Positive Rate', **axis_font)\n",
    "    ax1.set_title(\"Roc analysis\",  **title_font)\n",
    "    ax1.legend(loc=\"lower right\", prop= font_prop)\n",
    "    \n",
    "    cm = confusion_matrix(true_values, predictions)\n",
    "    cm_n = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_f = [[1,0],[1,0]]\n",
    "    \n",
    "    mask1 = [[0,  1], [1, 0]]\n",
    "    mask2 = [[1,  0], [0, 1]]\n",
    "    cm1 = masked_array(cm_n,mask1)\n",
    "    cm2 = masked_array(cm_n,mask2)\n",
    "    cm1f = masked_array(cm_f,mask1)\n",
    "    cm2f = masked_array(cm_f,mask2)\n",
    "    \n",
    "    cmap1=plt.cm.get_cmap(\"correct\")\n",
    "    cmap2=plt.cm.get_cmap(\"wrong\")\n",
    "    \n",
    "    p2f = ax2.imshow(cm2f,interpolation='nearest',cmap=cmap2)\n",
    "    p1f = ax2.imshow(cm1f,interpolation='nearest',cmap=cmap1)\n",
    "   \n",
    "    p2 = ax2.imshow(cm2,interpolation='nearest',cmap=cmap2)\n",
    "    p1 = ax2.imshow(cm1,interpolation='nearest',cmap=cmap1)\n",
    "    \n",
    "    cb2 = plt.colorbar(p2,shrink=0.5)\n",
    "    cb2.set_clim(0, 1)\n",
    "    cb2.remove()\n",
    "    \n",
    "    cb1 = plt.colorbar(p1,shrink=0.5)\n",
    "    cb1.set_clim(0, 1)\n",
    "    cb1.remove()\n",
    "    \n",
    "    cb2 = plt.colorbar(p2f,shrink=0.5)\n",
    "    cb2.set_clim(0, cm1.sum())\n",
    "    cb2.ax.get_xaxis().labelpad = 10\n",
    "    cb2.ax.set_xlabel('False', **cb_font)\n",
    "    cb2.ax.tick_params(labelsize=15)\n",
    "\n",
    "    cb1 = plt.colorbar(p1f,shrink=0.5)\n",
    "    cb1.set_clim(0, cm1.sum())\n",
    "    cb1.ax.get_xaxis().labelpad = 10\n",
    "    cb1.ax.set_xlabel('True', **cb_font)\n",
    "    cb1.ax.tick_params(labelsize=15)\n",
    "\n",
    "    ax2.grid(False)\n",
    "\n",
    "    ax2.set_title(\"Confusion matrix\\n\\nACC: %0.3f   F1: %0.3f   MCC: %0.3f\" % (acc, f1, mcc_max), **title_font)\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax2.set_xticks(tick_marks)\n",
    "    ax2.set_yticks(tick_marks)\n",
    "    ax2.set_xticklabels(classes)\n",
    "    ax2.set_yticklabels(classes)\n",
    "    \n",
    "    thresh = 0.6\n",
    "\n",
    "    ax2.text(0, 0, \"%d\\n(%0.2f)\" % (cm[0,0], cm_n[0,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 1, \"%d\\n(%0.2f)\" % (cm[1,1], cm_n[1,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 0, \"%d\\n(%0.2f)\" % (cm[0,1], cm_n[0,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(0, 1, \"%d\\n(%0.2f)\" % (cm[1,0], cm_n[1,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "\n",
    "    ax2.set_ylabel('True label', **axis_font)\n",
    "    ax2.set_xlabel('Predicted label', **axis_font)\n",
    "    \n",
    "    for label in (ax2.get_xticklabels() + ax2.get_yticklabels() + ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "        label.set_fontsize(13)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=20)   \n",
    "    \n",
    "    plt.tight_layout(pad=1, w_pad=1, h_pad=1)\n",
    "    plt.savefig(\"%s/output/python/h2o/images/%s.png\" % (main_dir, fig_name))\n",
    "    plt.show()\n",
    "    prediction_string = \",\".join(str(x) for x in predictions)\n",
    "    return \"%0.5f,%0.5f,%0.5f,%0.5f,%0.5f,%d,%d,%d,%d,%0.5f,%0.5f,%0.5f,%0.5f,*%s*\" % (prediction_auc,acc,f1, mcc_max,threshold,cm[0,0],cm[1,1],cm[0,1],cm[1,0], cm_n[0,0],cm_n[1,1],cm_n[0,1],cm_n[1,0], prediction_string)\n",
    "    \n",
    "def print_save_single_roc_threshold_f1(true_values, predictions, title, fig_name):\n",
    "    fpr, tpr, thresholds = roc_curve(true_values, predictions)\n",
    "    prediction_auc = auc(fpr, tpr)\n",
    "    \n",
    "    f1_max, threshold, predictions = find_max_f1_threshold(true_values, predictions, thresholds)\n",
    "    acc = accuracy_score(true_values, predictions)\n",
    "    mcc = matthews_corrcoef(true_values, predictions)\n",
    "    th_index = thresholds.tolist().index(threshold)\n",
    "\n",
    "    title_font = {'size':'17', 'color':'black', 'weight':'normal', 'verticalalignment':'bottom'}\n",
    "    axis_font = {'size':'15'}\n",
    "    cb_font = {'size':'15', 'horizontalalignment':'left'}\n",
    "    font_path = \"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\"\n",
    "    font_prop = font_manager.FontProperties(size=15)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    gs1 = gridspec.GridSpec(1, 2)\n",
    "    ax_list = [fig.add_subplot(ss) for ss in gs1]\n",
    "    ax1 =  ax_list[0]\n",
    "    ax2 =  ax_list[1]\n",
    "    lw = 2\n",
    "\n",
    "    ax1.scatter(fpr[th_index], tpr[th_index], s=75, c=\"red\", label='Optimal threshold \\n(cutoff = %0.4f)' % (threshold))\n",
    "    ax1.plot(fpr, tpr, color=\"black\", lw=lw, label='ROC curve (area = %0.4f)' % prediction_auc)\n",
    "    ax1.plot([0, 1], [0, 1], color='gray', lw=lw, linestyle='--')\n",
    "    ax1.set_xlim([0.0, 1.0])\n",
    "    ax1.set_ylim([0.0, 1.05])\n",
    "    ax1.set_xlabel('False Positive Rate', **axis_font)\n",
    "    ax1.set_ylabel('True Positive Rate', **axis_font)\n",
    "    ax1.set_title(\"Roc analysis\",  **title_font)\n",
    "    ax1.legend(loc=\"lower right\", prop= font_prop)\n",
    "    \n",
    "    cm = confusion_matrix(true_values, predictions)\n",
    "    cm_n = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_f = [[1,0],[1,0]]\n",
    "    \n",
    "    mask1 = [[0,  1], [1, 0]]\n",
    "    mask2 = [[1,  0], [0, 1]]\n",
    "    cm1 = masked_array(cm_n,mask1)\n",
    "    cm2 = masked_array(cm_n,mask2)\n",
    "    cm1f = masked_array(cm_f,mask1)\n",
    "    cm2f = masked_array(cm_f,mask2)\n",
    "    \n",
    "    cmap1=plt.cm.get_cmap(\"correct\")\n",
    "    cmap2=plt.cm.get_cmap(\"wrong\")\n",
    "    \n",
    "    p2f = ax2.imshow(cm2f,interpolation='nearest',cmap=cmap2)\n",
    "    p1f = ax2.imshow(cm1f,interpolation='nearest',cmap=cmap1)\n",
    "   \n",
    "    p2 = ax2.imshow(cm2,interpolation='nearest',cmap=cmap2)\n",
    "    p1 = ax2.imshow(cm1,interpolation='nearest',cmap=cmap1)\n",
    "    \n",
    "    cb2 = plt.colorbar(p2,shrink=0.5)\n",
    "    cb2.set_clim(0, 1)\n",
    "    cb2.remove()\n",
    "    \n",
    "    cb1 = plt.colorbar(p1,shrink=0.5)\n",
    "    cb1.set_clim(0, 1)\n",
    "    cb1.remove()\n",
    "    \n",
    "    cb2 = plt.colorbar(p2f,shrink=0.5)\n",
    "    cb2.set_clim(0, cm1.sum())\n",
    "    cb2.ax.get_xaxis().labelpad = 10\n",
    "    cb2.ax.set_xlabel('False', **cb_font)\n",
    "    cb2.ax.tick_params(labelsize=15)\n",
    "\n",
    "    cb1 = plt.colorbar(p1f,shrink=0.5)\n",
    "    cb1.set_clim(0, cm1.sum())\n",
    "    cb1.ax.get_xaxis().labelpad = 10\n",
    "    cb1.ax.set_xlabel('True', **cb_font)\n",
    "    cb1.ax.tick_params(labelsize=15)\n",
    "\n",
    "    ax2.grid(False)\n",
    "\n",
    "    ax2.set_title(\"Confusion matrix\\n\\nACC: %0.3f   F1: %0.3f   MCC: %0.3f\" % (acc, f1_max, mcc), **title_font)\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax2.set_xticks(tick_marks)\n",
    "    ax2.set_yticks(tick_marks)\n",
    "    ax2.set_xticklabels(classes)\n",
    "    ax2.set_yticklabels(classes)\n",
    "    \n",
    "    thresh = 0.6\n",
    "\n",
    "    ax2.text(0, 0, \"%d\\n(%0.2f)\" % (cm[0,0], cm_n[0,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 1, \"%d\\n(%0.2f)\" % (cm[1,1], cm_n[1,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 0, \"%d\\n(%0.2f)\" % (cm[0,1], cm_n[0,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(0, 1, \"%d\\n(%0.2f)\" % (cm[1,0], cm_n[1,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "\n",
    "    ax2.set_ylabel('True label', **axis_font)\n",
    "    ax2.set_xlabel('Predicted label', **axis_font)\n",
    "    \n",
    "    for label in (ax2.get_xticklabels() + ax2.get_yticklabels() + ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "        label.set_fontsize(13)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=20)   \n",
    "    \n",
    "    plt.tight_layout(pad=1, w_pad=1, h_pad=1)\n",
    "    plt.savefig(\"%s/output/python/h2o/images/%s.png\" % (main_dir, fig_name))\n",
    "    plt.show()\n",
    "    prediction_string = \",\".join(str(x) for x in predictions)\n",
    "    return \"%0.5f,%0.5f,%0.5f,%0.5f,%0.5f,%d,%d,%d,%d,%0.5f,%0.5f,%0.5f,%0.5f,%s\" % (prediction_auc,acc,f1_max,mcc,threshold,cm[0,0],cm[1,1],cm[0,1],cm[1,0], cm_n[0,0],cm_n[1,1],cm_n[0,1],cm_n[1,0], prediction_string)\n",
    "    \n",
    "\n",
    "def print_save_single_prc_threshold(true_values, predictions, title, fig_name):\n",
    "    precision, recall, thresholds = precision_recall_curve(true_values, predictions)\n",
    "    average_precision = average_precision_score(true_values, predictions)\n",
    "    \n",
    "    mcc_max, threshold, predictions = find_max_mcc_threshold(true_values, predictions, thresholds)\n",
    "    acc = accuracy_score(true_values, predictions)\n",
    "    f1 = f1_score(true_values, predictions)\n",
    "    th_index = thresholds.tolist().index(threshold)\n",
    "\n",
    "    title_font = {'size':'17', 'color':'black', 'weight':'normal', 'verticalalignment':'bottom'}\n",
    "    axis_font = {'size':'15'}\n",
    "    cb_font = {'size':'15', 'horizontalalignment':'left'}\n",
    "    font_path = \"/usr/share/fonts/truetype/msttcorefonts/Arial.ttf\"\n",
    "    font_prop = font_manager.FontProperties(size=15)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    gs1 = gridspec.GridSpec(1, 2)\n",
    "    ax_list = [fig.add_subplot(ss) for ss in gs1]\n",
    "    ax1 =  ax_list[0]\n",
    "    ax2 =  ax_list[1]\n",
    "    lw = 2\n",
    "\n",
    "    \n",
    "    ax1.scatter(recall[th_index], precision[th_index], s=75, c=\"red\", label='Optimal threshold \\n(cutoff = %0.4f,' % (threshold))\n",
    "    ax1.plot(precision, recall, color='black', lw=lw, label='PRC curve (area = {1:0.4f})'.format(average_precision))\n",
    "    ratio = len(true_values[true_values == 1])/len(true_values[true_values == 0])\n",
    "    ax1.plot([ratio, ratio], color='gray', lw=lw, linestyle='--')\n",
    "    ax1.set_xlim([0.0, 0.5])\n",
    "    ax1.set_ylim([0.0, 0.2])\n",
    "    ax1.set_xlabel('Recall',  **axis_font)\n",
    "    ax1.set_ylabel('Precision', **axis_font)\n",
    "    ax1.set_title(\"PRC analysis\", **title_font)\n",
    "    ax1.set_legend(loc=\"upper right\", prop=font_prop)\n",
    "    \n",
    "    cm = confusion_matrix(true_values, predictions)\n",
    "    cm_n = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_f = [[1,0],[1,0]]\n",
    "    \n",
    "    mask1 = [[0,  1], [1, 0]]\n",
    "    mask2 = [[1,  0], [0, 1]]\n",
    "    cm1 = masked_array(cm_n,mask1)\n",
    "    cm2 = masked_array(cm_n,mask2)    \n",
    "    cm1f = masked_array(cm_f,mask1)\n",
    "    cm2f = masked_array(cm_f,mask2)\n",
    "    \n",
    "    cmap1=plt.cm.get_cmap(\"correct\")\n",
    "    cmap2=plt.cm.get_cmap(\"wrong\")\n",
    "    \n",
    "    p2f = ax2.imshow(cm2f,interpolation='nearest',cmap=cmap2)\n",
    "    p1f = ax2.imshow(cm1f,interpolation='nearest',cmap=cmap1)\n",
    "    \n",
    "    p2 = ax2.imshow(cm2,interpolation='nearest',cmap=cmap2)\n",
    "    p1 = ax2.imshow(cm1,interpolation='nearest',cmap=cmap1)\n",
    "    \n",
    "    cb2 = plt.colorbar(p2,shrink=0.5)\n",
    "    cb2.set_clim(0, 1)\n",
    "    cb2.remove()\n",
    "    cb1 = plt.colorbar(p1,shrink=0.5)\n",
    "    cb1.set_clim(0, 1)\n",
    "    cb1.remove()\n",
    "        \n",
    "    cb2 = plt.colorbar(p2,shrink=0.5)\n",
    "    cb2.set_clim(0, cm.sum())\n",
    "    cb2.ax.get_xaxis().labelpad = 10\n",
    "    cb2.ax.set_xlabel('False', **cb_font)\n",
    "    cb2.ax.tick_params(labelsize=15)\n",
    "    \n",
    "    cb1 = plt.colorbar(p1,shrink=0.5)\n",
    "    cb1.set_clim(0, cm.sum())\n",
    "    cb1.ax.get_xaxis().labelpad = 10\n",
    "    cb1.ax.set_xlabel('True', **cb_font)\n",
    "    cb1.ax.tick_params(labelsize=15)\n",
    "\n",
    "    ax2.grid(False)\n",
    "\n",
    "    ax2.set_title(\"Confusion matrix\\n\\nACC: %0.3f   F1: %0.3f   MCC: %0.3f\" % (acc, f1, mcc_max), **title_font)\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax2.set_xticks(tick_marks)\n",
    "    ax2.set_yticks(tick_marks)\n",
    "    ax2.set_xticklabels(classes)\n",
    "    ax2.set_yticklabels(classes)\n",
    "\n",
    "    thresh = 0.6\n",
    "\n",
    "    ax2.text(0, 0, \"%d\\n(%0.2f)\" % (cm[0,0], cm_n[0,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 1, \"%d\\n(%0.2f)\" % (cm[1,1], cm_n[1,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(1, 0, \"%d\\n(%0.2f)\" % (cm[0,1], cm_n[0,1]), horizontalalignment=\"center\", color=\"white\" if cm_n[0, 1] > thresh else \"black\", fontproperties=font_prop)\n",
    "    ax2.text(0, 1, \"%d\\n(%0.2f)\" % (cm[1,0], cm_n[1,0]), horizontalalignment=\"center\", color=\"white\" if cm_n[1, 0] > thresh else \"black\", fontproperties=font_prop)\n",
    "\n",
    "    ax2.set_ylabel('True label', **axis_font)\n",
    "    ax2.set_xlabel('Predicted label', **axis_font)\n",
    "    \n",
    "    for label in (ax2.get_xticklabels() + ax2.get_yticklabels() + ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "\n",
    "        label.set_fontsize(13)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=20)   \n",
    "    \n",
    "    plt.tight_layout(pad=4, w_pad=2, h_pad=1)\n",
    "    plt.savefig(\"%s/images/%s.png\" % (main_dir, fig_name))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_variable_importance(variables, scaled_importance, fig_name):\n",
    "    var_n = len(variables)\n",
    "    variables_axis = copy.deepcopy(variables)\n",
    "    for i in range(var_n):\n",
    "        variables_axis[i] = \"%s (%0.2f)\" % (variables[i], scaled_importance[i])\n",
    "    if var_n > 30 :\n",
    "        fig, ax = plt.subplots(figsize=(7,17))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(7,10))\n",
    "    y_pos = np.arange(var_n)\n",
    "    ax.barh(y_pos, scaled_importance, align='center', color='black', ecolor='black')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(variables_axis)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Scaled Importance')\n",
    "    ax.set_ylabel('Variable')\n",
    "    \n",
    "    plt.tight_layout(pad=1, w_pad=1, h_pad=1)\n",
    "    plt.savefig(\"%s/output/python/h2o/images/%s.png\" % (main_dir, fig_name))\n",
    "    plt.show()\n",
    "    table = np.stack([variables, scaled_importance], axis=1)\n",
    "    np.savetxt(\"%s/output/python/h2o/images/%s_table.csv\" % (main_dir, fig_name), table, fmt=\"%s\", delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Default models\n",
    "\n",
    "X_date = ['id', 'x200', 'y200', 'idx200', 'idy200', 'Y', 'Mo', 'W','WD', 'D', 'MoCat', 'vzdbcs', 'vzdpostabanka', \n",
    " 'vzdprodejna','vzdrestaurace','lokalitarelevance','datodHCat_1', 'datodHCat_2', 'datodHCat_3', 'datodHCat_4','datodHCat_5',\n",
    " 'stavobj_A','stavobj_B', 'stavobj_C','stavobj_D','stavobj_F','stavobj_G']\n",
    "\n",
    "X_tm = ['id', 'x200', 'y200', 'Y', 'Mo', 'W','WD', 'D', 'MoCat', 'vzdbcs', 'vzdpostabanka', \n",
    " 'vzdprodejna','vzdrestaurace','datodHCat_1', 'datodHCat_2', 'datodHCat_3', 'datodHCat_4','datodHCat_5',\n",
    " 'stavobj_A','stavobj_B', 'stavobj_C','stavobj_D','stavobj_F','stavobj_G', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd10', 'd11', 'd12', 'd13', 'd14', \n",
    " 'd15', 'd16', 'd17', 'd18', 'd19', 'd20', 'd21']\n",
    "\n",
    "X_neigh = ['id', 'x200', 'y200', 'idx200', 'idy200', 'Y', 'Mo', 'W','WD', 'D', 'MoCat', 'vzdbcs', 'vzdpostabanka', \n",
    " 'vzdprodejna','vzdrestaurace','lokalitarelevance','datodHCat_1', 'datodHCat_2', 'datodHCat_3', 'datodHCat_4','datodHCat_5',\n",
    " 'stavobj_A','stavobj_B', 'stavobj_C','stavobj_D','stavobj_F','stavobj_G',\n",
    "  '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n",
    "       '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
    "       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35',\n",
    "       '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46',\n",
    "       '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57',\n",
    "       '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68',\n",
    "       '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79',\n",
    "       '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90',\n",
    "       '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101',\n",
    "       '102', '103', '104', '105', '106', '107', '108', '109', '110',\n",
    "       '111', '112', '113', '114', '115', '116', '117', '118', '119',\n",
    "       '120']\n",
    "\n",
    "X_all = ['id', 'x200', 'y200', 'idx200', 'idy200', 'Y', 'Mo', 'W','WD', 'D', 'MoCat', 'vzdbcs', 'vzdpostabanka', \n",
    " 'vzdprodejna','vzdrestaurace', 'lokalitarelevance', 'datodHCat_1', 'datodHCat_2', 'datodHCat_3', 'datodHCat_4','datodHCat_5',\n",
    " 'stavobj_A','stavobj_B', 'stavobj_C','stavobj_D','stavobj_F','stavobj_G',\n",
    "  '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n",
    "    '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
    "    '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35',\n",
    "    '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46',\n",
    "    '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57',\n",
    "    '58', '59', '61', '62', '63', '64', '65', '66', '67', '68',\n",
    "    '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79',\n",
    "    '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90',\n",
    "    '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101',\n",
    "    '102', '103', '104', '105', '106', '107', '108', '109', '110',\n",
    "    '111', '112', '113', '114', '115', '116', '117', '118', '119',\n",
    "    '120', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd10', \n",
    "    'd11', 'd12', 'd13', 'd14','d15', 'd16', 'd17', 'd18', 'd19', 'd20', 'd21','PCA_0', 'PCA_1', 'PCA_2', 'PCA_3', 'PCA_4']\n",
    "\n",
    "X_fs = ['PCA_0', 'vzdrestaurace', 'd21', 'd15', 'd7', 'd20', 'd10', 'd8', 'PCA_4', 'vzdpostabanka', \n",
    "        'd19', 'd1', 'd17', 'd2', 'd4', 'd9', 'd5', 'd16', 'd6', 'd18', 'd3', 'd13', 'stavobj_C', 'datodHCat_5', 'datodHCat_4', \n",
    "        'stavobj_F', 'Y', 'D', 'vzdprodejna','datodHCat_3', 'datodHCat_2', 'x200', 'PCA_1', 'PCA_3', 'd14', 'idx200', \n",
    "        '71', 'datodHCat_1', '49', 'WD', '59']\n",
    "\n",
    "y = 'crimecount_x'\n",
    "\n",
    "result_file_dir = \"%s/output/python/model_results.csv\" % main_dir\n",
    "\n",
    "def train_test_model_save_results_h2o(model, model_id, data_id, X, train = False, selection = False, n_select = 0):\n",
    "    if train:\n",
    "        model.train(x=X, y=y, training_frame=trainH2o, validation_frame=validationH2o)\n",
    "    print(\"save\")\n",
    "    path = h2o.save_model(model=model, path=\"%s/output/python/h2o/models\" % main_dir, force=True)\n",
    "    print(\"predict\")\n",
    "    prediction = model.predict(testH2o).as_data_frame()[\"p1\"].values\n",
    "    print(\"roc\")\n",
    "    result_line = print_save_single_roc_threshold(true_values, prediction, \"\", \"roc_%s_%s_th\" % (data_id, model_id))\n",
    "    params = str(model.params)\n",
    "    with open(result_file_dir, 'a') as file:\n",
    "        file.write(\"%s,%s,%s,%s,*%s*\\n\" % (model_id, data_id, path, result_line, params))\n",
    "    if model._model_json['output']['variable_importances']:\n",
    "        variables = model._model_json['output']['variable_importances']['variable']\n",
    "        scaled_importance = model._model_json['output']['variable_importances']['scaled_importance']\n",
    "        plot_variable_importance(variables, scaled_importance, \"vi_%s_%s\" % (data_id, model_id))\n",
    "        if selection:\n",
    "            Xv = variables[:n_select]\n",
    "            train_test_model_save_results_h2o(model, model_id+\"_FS\", data_id, Xv, True)\n",
    "        \n",
    "data_ids = [\"tm_data\", \"neigh_data\", \"all_data\", \"fs_data\"]\n",
    "Xs = [X_tm, X_neigh, X_all, X_fs]\n",
    "model_ids = [\"drf\", \"gbm\", \"dl\"]\n",
    "\n",
    "def grid_search(model, hyperparameters, search_criteria, X, grid_id):\n",
    "    grid_models = H2OGridSearch(model, hyperparameters, search_criteria=search_criteria, grid_id = grid_id)\n",
    "    grid_models.train(x=X,y=y, training_frame=trainH2o, validation_frame=validationH2o)\n",
    "    grid_models = grid_models.get_grid(sort_by = \"AUC\", decreasing=True)\n",
    "    return grid_models\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {'ntrees':[20,40,50,70,90,100,150], 'max_depth':[5,10,30,50,100]}\n",
    "search_criteria = {'strategy': \"RandomDiscrete\", 'seed': 42,\n",
    "            'stopping_metric': \"AUC\", 'stopping_tolerance': 0.01,\n",
    "            'stopping_rounds': 5}\n",
    "\n",
    "\n",
    "setting = \"grid\"\n",
    "model_id = \"drf\"\n",
    "\n",
    "hyperparameters = {'ntrees':[30,40,60], 'max_depth':[5,10,30,50]}\n",
    "search_criteria = {'strategy': \"RandomDiscrete\", 'seed': 42,\n",
    "            'stopping_metric': \"AUC\", 'stopping_tolerance': 0.01,\n",
    "            'stopping_rounds': 5}\n",
    "setting = \"grid\"\n",
    "model_id = \"gbm\"\n",
    "\n",
    "data_id = \"pca\"\n",
    "\n",
    "y = 'crimecount'\n",
    "\n",
    "X = [\"PCA_0\",\"PCA_1\",\n",
    "\"PCA_2\",\"PCA_3\",\"PCA_4\", \"PCA_5\",\"PCA_6\",\"PCA_7\",\"PCA_8\",\"PCA_9\",\"PCA_10\",\"PCA_11\",\"PCA_12\",\"PCA_13\",\"PCA_14\",\n",
    "\"PCA_15\",\"PCA_16\",\"PCA_17\",\"PCA_18\",\"PCA_19\",\"PCA_20\",\"PCA_21\",\"PCA_22\",\"PCA_23\",\"PCA_24\",\n",
    "\"PCA_25\",\"PCA_26\",\"PCA_27\",\"PCA_28\",\"PCA_29\",\"PCA_30\",\"PCA_31\",\"PCA_32\",\"PCA_33\",\"PCA_34\",\n",
    "\"PCA_35\",\"PCA_36\",\"PCA_37\",\"PCA_38\",\"PCA_39\",\"PCA_40\",\"PCA_41\",\"PCA_42\",\"PCA_43\",\"PCA_44\",\n",
    "\"PCA_45\",\"PCA_46\",\"PCA_47\",\"PCA_48\",\"PCA_49\",\"PCA_50\",\"PCA_51\",\"PCA_52\",\"PCA_53\",\"PCA_54\",\n",
    "\"PCA_55\",\"PCA_56\",\"PCA_57\",\"PCA_58\",\"PCA_59\",\"PCA_60\",\"PCA_61\",\"PCA_62\",\"PCA_63\",\"PCA_64\",\n",
    "\"PCA_65\",\"PCA_66\",\"PCA_67\",\"PCA_68\",\"PCA_69\",\"PCA_70\",\"PCA_71\",\"PCA_72\",\"PCA_73\",\"PCA_74\",\n",
    "\"PCA_75\",\"PCA_76\",\"PCA_77\",\"PCA_78\",\"PCA_79\",\"PCA_80\",\"PCA_81\",\"PCA_82\",\"PCA_83\",\"PCA_84\",\n",
    "\"PCA_85\",\"PCA_86\",\"PCA_87\",\"PCA_88\",\"PCA_89\",\"PCA_90\",\"PCA_91\",\"PCA_92\",\"PCA_93\",\"PCA_94\",\n",
    "\"PCA_95\",\"PCA_96\",\"PCA_97\",\"PCA_98\",\"PCA_99\",\"PCA_100\",\"PCA_101\",\"PCA_102\",\"PCA_103\",\"PCA_104\",\n",
    "\"PCA_105\",\"PCA_106\",\"PCA_107\",\"PCA_108\",\"PCA_109\",\"PCA_110\",\"PCA_111\",\"PCA_112\",\"PCA_113\",\"PCA_114\",\n",
    "\"PCA_115\",\"PCA_116\",\"PCA_117\",\"PCA_118\",\"PCA_119\",\"PCA_120\",\"PCA_121\",\"PCA_122\",\"PCA_123\",\"PCA_124\",\n",
    "\"PCA_125\",\"PCA_126\",\"PCA_127\",\"PCA_128\",\"PCA_129\",\"PCA_130\",\"PCA_131\",\"PCA_132\",\"PCA_133\",\"PCA_134\",\n",
    "\"PCA_135\",\"PCA_136\",\"PCA_137\",\"PCA_138\",\"PCA_139\",\"PCA_140\",\"PCA_141\",\"PCA_142\",\"PCA_143\",\"PCA_144\",\n",
    "\"PCA_145\",\"PCA_146\",\"PCA_147\",\"PCA_148\",\"PCA_149\",\"PCA_150\",\"PCA_151\",\"PCA_152\",\"PCA_153\",\"PCA_154\",\n",
    "\"PCA_155\",\"PCA_156\",\"PCA_157\",\"PCA_158\",\"PCA_159\",\"PCA_160\",\"PCA_161\",\"PCA_162\"]\n",
    "\n",
    "\n",
    "#model = H2ORandomForestEstimator(model_id = \"%s_%s_%s\" % (model_id, data_id, setting))\n",
    "#model = H2ORandomForestEstimator(model_id = model_id+\"_\"+data_id,  min_rows=20)\n",
    "model = H2OGradientBoostingEstimator(model_id = model_id+\"_\"+data_id,  min_rows=20)\n",
    "\n",
    "models = grid_search(model, hyperparameters, search_criteria, X, model_id+\"_\"+data_id+\"_\"+setting)\n",
    "\n",
    "models_length = len(models)\n",
    "if models_length > 3:\n",
    "    models_length = 3\n",
    "    \n",
    "for j in range(models_length):\n",
    "    if data_id == \"all_data\":\n",
    "        train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X, False,  True, 42)\n",
    "    else:\n",
    "        train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = H2ORandomForestEstimator(model_id = \"%s_%s_%s\" % (model_id, data_id, setting))\n",
    "model.train(x=Xs[0], y=y, training_frame=trainH2o, validation_frame=validationH2o)\n",
    "prediction = model.predict(testH2o).as_data_frame()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Default models\n",
    "setting = \"default\"\n",
    "\n",
    "for i in range(len(data_ids)):\n",
    "    data_id = data_ids[i]\n",
    "    X = Xs[i]\n",
    "    for j in range(len(model_ids)):\n",
    "        model_id = model_ids[j]\n",
    "        print(\"%s_%s\" % (model_id, data_id))\n",
    "        if model_id  == \"drf\":\n",
    "            model = H2ORandomForestEstimator(model_id = \"%s_%s_%s\" % (model_id, data_id, setting))\n",
    "        elif model_id  == \"gbm\":\n",
    "            model = H2OGradientBoostingEstimator(model_id = \"%s_%s_%s\" % (model_id, data_id, setting))\n",
    "        elif model_id == \"dl\":\n",
    "            model = H2ODeepLearningEstimator(model_id = \"%s_%s_%s\" % (model_id, data_id, setting))\n",
    "            \n",
    "        if data_id == \"all_data\":\n",
    "            train_test_model_save_results_h2o(model, model_id+\"_\"+setting, data_id, X, True, True, 42)\n",
    "        else:\n",
    "            train_test_model_save_results_h2o(model, model_id+\"_\"+setting, data_id, X, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters drf\n",
    "hyperparameters = {'ntrees':[20,40,50,70,90,100,150], 'max_depth':[5,10,30,50,100]}\n",
    "search_criteria = {'strategy': \"RandomDiscrete\", 'seed': 42,\n",
    "            'stopping_metric': \"AUC\", 'stopping_tolerance': 0.01,\n",
    "            'stopping_rounds': 5}\n",
    "setting = \"grid\"\n",
    "model_id = \"drf\"\n",
    "\n",
    "for i in range(len(data_ids)):\n",
    "    data_id = data_ids[i]\n",
    "    X = Xs[i]\n",
    "    model = H2ORandomForestEstimator(model_id = model_id+\"_\"+data_id, min_rows=20)\n",
    "    models = grid_search(model, hyperparameters, search_criteria, X, model_id+\"_\"+data_id+\"_\"+setting)\n",
    "    \n",
    "    models_length = len(models)\n",
    "    if models_length > 3:\n",
    "        models_length = 3\n",
    "\n",
    "    for j in range(models_length):\n",
    "        print(model_id+str(j)+\"_\"+setting+\"_\"+data_id)\n",
    "        if data_id == \"all_data\":\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X, False, True, 42)\n",
    "        else:\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters gbm\n",
    "\n",
    "hyperparameters = {'ntrees':[20,30,40,50,60,70], 'max_depth':[5,10,30,50]}\n",
    "search_criteria = {'strategy': \"RandomDiscrete\", 'seed': 42,\n",
    "            'stopping_metric': \"AUC\", 'stopping_tolerance': 0.01,\n",
    "            'stopping_rounds': 5}\n",
    "setting = \"grid\"\n",
    "model_id = \"gbm\"\n",
    "\n",
    "for i in range(len(data_ids)):\n",
    "    data_id = data_ids[i]\n",
    "    X = Xs[i]\n",
    "    model = H2OGradientBoostingEstimator(model_id = model_id+\"_\"+data_id,  min_rows=20)\n",
    "    models = grid_search(model, hyperparameters, search_criteria, X, model_id+\"_\"+data_id+\"_\"+setting)\n",
    "\n",
    "    models_length = len(models)\n",
    "    if models_length > 3:\n",
    "        models_length = 3\n",
    "    \n",
    "    for j in range(models_length):\n",
    "        if data_id == \"all_data\":\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X, False,  True, 42)\n",
    "        else:\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#https://www.slideshare.net/0xdata/h2o-world-top-10-deep-learning-tips-tricks-arno-candel\n",
    "# hyperparameters dl\n",
    "\n",
    "hyperparameters = {'hidden':[[100,100], [512], [16,16,16,16,16], [32,32,32,32,32], [64,64,64]], 'input_dropout_ratio': [0.2, 0.3, 0.4]}\n",
    "search_criteria = { 'strategy': \"RandomDiscrete\", 'seed': 42,\n",
    "            'stopping_metric': \"AUC\", 'stopping_tolerance': 0.01,\n",
    "            'stopping_rounds': 5}\n",
    "setting = \"grid\"\n",
    "model_id = \"dl\"\n",
    "\n",
    "for i in range(len(data_ids)):\n",
    "    data_id = data_ids[i]\n",
    "    X = Xs[i]\n",
    "    model = H2ODeepLearningEstimator(model_id = model_id+\"_\"+data_id,\n",
    "                                      score_validation_sampling='Stratified',\n",
    "                                      l1=0.0001,  l2=0.0001)\n",
    "    models = grid_search(model, hyperparameters, search_criteria, X, model_id+\"_\"+data_id+\"_\"+setting)\n",
    "\n",
    "    models_length = len(models)\n",
    "    if models_length > 3:\n",
    "        models_length = 3\n",
    "    \n",
    "    for j in range(models_length):\n",
    "        if data_id == \"all_data\":\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X, False, True, 30)\n",
    "        else:\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#https://www.slideshare.net/0xdata/h2o-world-top-10-deep-learning-tips-tricks-arno-candel\n",
    "# hyperparameters dl\n",
    "\n",
    "hyperparameters = {'hidden':[[16,16,16,16,16,16], [32,32,32,32,32,32,32,32], [64,64,64,64,64], [96,96,96,96,96]], 'input_dropout_ratio': [0.2, 0.3, 0.4, 0.5, 0.6]}\n",
    "search_criteria = {'strategy': \"RandomDiscrete\", 'seed': 42,\n",
    "            'stopping_metric': \"F1\", 'stopping_tolerance': 0.01,\n",
    "            'stopping_rounds': 2}\n",
    "setting = \"grid2\"\n",
    "model_id = \"dl\"\n",
    "\n",
    "for i in range(len(data_ids)):\n",
    "    data_id = data_ids[i]\n",
    "    X = Xs[i]\n",
    "    model = H2ODeepLearningEstimator(model_id = model_id+\"_\"+data_id,\n",
    "                                      score_validation_sampling='Stratified', \n",
    "                                      stopping_rounds=5,  \n",
    "                                      l1=0.0001,  l2=0.0001)\n",
    "    models = grid_search(model, hyperparameters, search_criteria, X, model_id+\"_\"+data_id+\"_\"+setting)\n",
    "\n",
    "    for j in range(3):\n",
    "        if data_id == \"all_data\":\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X, False, True, 42)\n",
    "        else:\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#https://www.slideshare.net/0xdata/h2o-world-top-10-deep-learning-tips-tricks-arno-candel\n",
    "# hyperparameters dl\n",
    "\n",
    "hyperparameters = {'hidden':[[16,16,16], [32,32,32], [64,64,64], [96,96,96]], 'input_dropout_ratio': [0.2, 0.3, 0.4, 0.5, 0.6]}\n",
    "search_criteria = { 'strategy': \"RandomDiscrete\", 'seed': 42,\n",
    "            'stopping_metric': \"F1\", 'stopping_tolerance': 0.1,\n",
    "            'stopping_rounds': 2}\n",
    "setting = \"grid2\"\n",
    "model_id = \"dl\"\n",
    "\n",
    "for i in range(len(data_ids)):\n",
    "    data_id = data_ids[i]\n",
    "    X = Xs[i]\n",
    "    model = H2ODeepLearningEstimator(model_id = model_id+\"_\"+data_id,\n",
    "                                      score_validation_sampling='Stratified', \n",
    "                                      l1=0.0001,  l2=0.0001)\n",
    "    models = grid_search(model, hyperparameters, search_criteria, X, model_id+\"_\"+data_id+\"_\"+setting)\n",
    "\n",
    "    for j in range(3):\n",
    "        if data_id == \"all_data\":\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X, False, True, 42)\n",
    "        else:\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Evaluation on test data - ROC, PRC\n",
    "\n",
    "true_values = test[\"crimecount_x\"]\n",
    "\n",
    "# The best case\n",
    "cm_base_best = confusion_matrix(true_values, true_values)\n",
    "mcc_base_best = matthews_corrcoef(true_values, true_values)\n",
    "acc = accuracy_score(true_values, true_values)\n",
    "f1 = f1_score(true_values, true_values)\n",
    "plot_and_save_bi_confusion_matrix(cm_base_best, \"cm_base_best\", \"ACC: %0.3f   F1: %0.3f   MCC: %0.3f\" % (acc, f1, mcc_base_best))\n",
    "print_save_single_roc_threshold(true_values, true_values*0.5, \"\", \"roc_base_best\")\n",
    "\n",
    "# The worst case\n",
    "prediction_worst = copy.deepcopy(true_values)\n",
    "prediction_worst[prediction_worst == 1] = -1\n",
    "prediction_worst[prediction_worst == 0] = 1\n",
    "mcc_base_worst = matthews_corrcoef(true_values, prediction_worst)\n",
    "prediction_worst[prediction_worst == -1] = 0\n",
    "cm_base_worst = confusion_matrix(true_values, prediction_worst)\n",
    "acc = accuracy_score(true_values, prediction_worst)\n",
    "f1 = f1_score(true_values, prediction_worst)\n",
    "plot_and_save_bi_confusion_matrix(cm_base_worst, \"cm_base_worst\", \"ACC: %0.3f   F1: %0.3f   MCC: %0.3f\" % (acc, f1, mcc_base_worst))\n",
    "#print_save_single_roc_threshold(true_values, prediction_worst/2, \"\", \"roc_base_worst\")\n",
    "\n",
    "# Base model - predict by zero\n",
    "prediction_base_zero = [0 for i in range(test.shape[0])]\n",
    "cm_base_zero = confusion_matrix(true_values, prediction_base_zero)\n",
    "mcc_prediction = copy.deepcopy(prediction_base_zero)\n",
    "mcc_prediction[mcc_prediction == 0] = -1\n",
    "mcc_base_zero = matthews_corrcoef(true_values, mcc_prediction)\n",
    "acc = accuracy_score(true_values, prediction_base_zero)\n",
    "f1 = f1_score(true_values, prediction_base_zero)\n",
    "plot_and_save_bi_confusion_matrix(cm_base_zero, \"cm_base_zero\", \"ACC: %0.3f   F1: %0.3f   MCC: %0.3f\" % (acc, f1, mcc_base_zero))\n",
    "#print_save_single_roc_threshold(true_values, prediction_base_zero, \"\", \"roc_base_zero\")\n",
    "\n",
    "# Base model - predict by one\n",
    "prediction_base_one = [1 for i in range(test.shape[0])]\n",
    "cm_base_one = confusion_matrix(true_values, prediction_base_one)\n",
    "mcc_base_one = matthews_corrcoef(true_values, prediction_base_one)\n",
    "mse_base_one = mean_squared_error(true_values, prediction_base_one)\n",
    "acc = accuracy_score(true_values, prediction_base_one)\n",
    "f1 = f1_score(true_values, prediction_base_one)\n",
    "plot_and_save_bi_confusion_matrix(cm_base_one, \"cm_base_one\", \"ACC: %0.3f   F1: %0.3f   MCC: %0.3f\" % (acc, f1, mcc_base_one))\n",
    "#print_save_single_roc_threshold(true_values, prediction_base_one, \"\", \"roc_base_one\")\n",
    "\n",
    "# Base model - predict by previous day\n",
    "prediction_base_prev = copy.deepcopy(test[\"d21\"])\n",
    "prediction_base_prev[prediction_base_prev > 0] = 1\n",
    "cm_base_prev = confusion_matrix(true_values, prediction_base_prev)\n",
    "mcc_prediction = copy.deepcopy(prediction_base_prev)\n",
    "mcc_prediction[mcc_prediction == 0] = -1\n",
    "mcc_base_prev = matthews_corrcoef(true_values, mcc_prediction)\n",
    "acc = accuracy_score(true_values, prediction_base_prev)\n",
    "f1 = f1_score(true_values, prediction_base_prev)\n",
    "plot_and_save_bi_confusion_matrix(cm_base_prev, \"cm_base_prev\",  \"ACC: %0.3f   F1: %0.3f   MCC: %0.3f\" % (acc, f1, mcc_base_prev))\n",
    "#print_save_single_roc_threshold(true_values, prediction_base_prev, \"\", \"roc_base_prev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Advanced models different data\n",
    "colors = sns.color_palette(\"hls\", 18)\n",
    "colors_drf = [colors[0], colors[1], colors[2], colors[3]]\n",
    "colors_gbm = [colors[4], colors[5], colors[6], colors[7]]\n",
    "colors_dl = [colors[8], colors[9], colors[10], colors[11]]\n",
    "\n",
    "\n",
    "#thresholds_drf1 = print_save_single_roc(true_values, prediction_drf1, colors_drf[0], \"\", \"roc_time_data_drf\")\n",
    "#thresholds_gbm1 = print_save_single_roc(true_values, prediction_gbm1, colors_gbm[0], \"\", \"roc_time_data_gbm\")\n",
    "#thresholds_dl1 = print_save_single_roc(true_values, prediction_dl1, colors_dl[0], \"\", \"roc_time_data_dl\")\n",
    "\n",
    "\n",
    "#thresholds_drf2 = print_save_single_roc(true_values, prediction_drf2, colors_drf[1], \"\", \"roc_time_loc_data_drf\")\n",
    "#thresholds_gbm2 = print_save_single_roc(true_values, prediction_gbm2, colors_gbm[1], \"\", \"roc_time_loc_data_gbm\")\n",
    "#thresholds_dl2 = print_save_single_roc(true_values, prediction_dl2, colors_dl[1], \"\", \"roc_time_loc_data_dl\")\n",
    "\n",
    "\n",
    "#thresholds_drf3 = print_save_single_roc(true_values, prediction_drf3, colors_drf[2], \"\", \"roc_tm_data_drf\")\n",
    "#thresholds_gbm3 = print_save_single_roc(true_values, prediction_gbm3, colors_gbm[2], \"\", \"roc_tm_data_gbm\")\n",
    "#thresholds_dl3 = print_save_single_roc(true_values, prediction_dl3, colors_dl[2], \"\", \"roc_tm_data_dl\")\n",
    "\n",
    "\n",
    "#thresholds_drf4 = print_save_single_roc(true_values, prediction_drf4, colors_drf[3], \"\", \"roc_neigh_data_drf\")\n",
    "#thresholds_gbm4 = print_save_single_roc(true_values, prediction_gbm4, colors_gbm[3], \"\", \"roc_neigh_data_gbm\")\n",
    "#thresholds_dl4 = print_save_single_roc(true_values, prediction_dl4, colors_dl[3], \"\", \"roc_neigh_data_DL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_names = [\"drf1\", \"gbm1\", \"dl1\", \"drf2\", \"gbm2\", \"dl2\", \"drf3\", \"gbm3\", \"dl3\",\n",
    "               \"drf4\", \"gbm4\", \"dl4\", \"drf5\", \"gbm5\", \"dl5\", \"drf6\", \"gbm6\", \"dl6\"]\n",
    "predictions = [prediction_drf1, prediction_gbm1, prediction_dl1, prediction_drf2, prediction_gbm2, prediction_dl2, \n",
    "               prediction_drf3, prediction_gbm3, prediction_dl3, prediction_drf4, prediction_gbm4, prediction_dl4,\n",
    "              prediction_drf5, prediction_gbm5, prediction_dl5, prediction_drf6, prediction_gbm6, prediction_dl6]\n",
    "\n",
    "colors_all = [colors[0], colors[6], colors[12], \n",
    "              colors[1], colors[7], colors[13], \n",
    "              colors[2], colors[8], colors[14], \n",
    "              colors[3], colors[9], colors[15], \n",
    "              colors[4], colors[10], colors[16], \n",
    "              colors[5], colors[11], colors[17]]\n",
    "\n",
    "n = 18\n",
    "\n",
    "# ROC all\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"roc_all\"\n",
    "print_save_multy_roc(true_values, predictions, n, model_names, colors_all, title, fig_name)\n",
    "\n",
    "# PRC all\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"prc_all\"\n",
    "print_save_multy_prc(true_values, predictions, n, model_names, colors_all, title, fig_name)\n",
    "\n",
    "# ROC and PRC all date data models\n",
    "\n",
    "model_names = [\"drf1\", \"gbm1\", \"dl1\"]\n",
    "predictions = [prediction_drf1, prediction_gbm1, prediction_dl1]\n",
    "n = 3\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"roc_all_time_data\"\n",
    "\n",
    "print_save_multy_roc(true_values, predictions, n, model_names, [colors[0], colors[6], colors[12]], title, fig_name)\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"prc_all_time_data\"\n",
    "print_save_multy_prc(true_values, predictions, n, model_names, [colors[0], colors[6], colors[12]], title, fig_name)\n",
    "\n",
    "\n",
    "# ROC and PRC time and local data\n",
    "\n",
    "model_names = [\"drf2\", \"gbm2\", \"dl2\"]\n",
    "predictions = [prediction_drf2, prediction_gbm2, prediction_dl2]\n",
    "n = 3\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"roc_all_time_local_data\"\n",
    "\n",
    "print_save_multy_roc(true_values, predictions, n, model_names, [colors[1], colors[7], colors[13]], title, fig_name)\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"prc_all_time_local_data\"\n",
    "print_save_multy_prc(true_values, predictions, n, model_names, [colors[1], colors[7], colors[13]], title, fig_name)\n",
    "\n",
    "\n",
    "# ROC and PRC time and local data + timeseries 21 days\n",
    "\n",
    "model_names = [\"drf3\", \"gbm3\", \"dl3\"]\n",
    "predictions = [prediction_drf3, prediction_gbm3, prediction_dl3]\n",
    "n = 3\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"roc_all_tm_data\"\n",
    "\n",
    "print_save_multy_roc(true_values, predictions, n, model_names, [colors[2], colors[8], colors[14]], title, fig_name)\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"prc_all_tm_data\"\n",
    "print_save_multy_prc(true_values, predictions, n, model_names, [colors[2], colors[8], colors[14]], title, fig_name)\n",
    "\n",
    "# ROC and PRC neigh data\n",
    "\n",
    "model_names = [\"drf4\", \"gbm4\", \"dl4\"]\n",
    "predictions = [prediction_drf4, prediction_gbm4, prediction_dl4]\n",
    "n = 3\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"roc_all_neigh_data\"\n",
    "\n",
    "print_save_multy_roc(true_values, predictions, n, model_names, [colors[3], colors[9], colors[15]], title, fig_name)\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"prc_all_neigh_data\"\n",
    "print_save_multy_prc(true_values, predictions, n, model_names, [colors[3], colors[9], colors[15]], title, fig_name)\n",
    "\n",
    "# ROC and PRC neigh data + local\n",
    "\n",
    "model_names = [\"drf5\", \"gbm5\", \"dl5\"]\n",
    "predictions = [prediction_drf5, prediction_gbm5, prediction_dl5]\n",
    "n = 3\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"roc_all_neigh_local_data\"\n",
    "\n",
    "print_save_multy_roc(true_values, predictions, n, model_names, [colors[4], colors[10], colors[16]], title, fig_name)\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"prc_all_neigh_local_data\"\n",
    "print_save_multy_prc(true_values, predictions, n, model_names, [colors[4], colors[10], colors[16]], title, fig_name)\n",
    "\n",
    "# ROC and PRC neigh data\n",
    "\n",
    "model_names = [\"drf6\", \"gbm6\", \"dl6\"]\n",
    "predictions = [prediction_drf6, prediction_gbm6, prediction_dl6]\n",
    "n = 3\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"roc_all_neigh_tm_data\"\n",
    "\n",
    "print_save_multy_roc(true_values, predictions, n, model_names, [colors[5], colors[11], colors[17]], title, fig_name)\n",
    "\n",
    "title = \"\"\n",
    "fig_name = \"prc_all_neigh_tm_data\"\n",
    "print_save_multy_prc(true_values, predictions, n, model_names, [colors[5], colors[11], colors[17]], title, fig_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h2o.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#data.columns.values\n",
    "#columns= ['id', 'date', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9',\n",
    "#       'd10', 'd11', 'd12', 'd13', 'd14', 'd15', 'd16', 'd17', 'd18',\n",
    "#       'd19', 'd20', 'd21','datodHCat_1', 'datodHCat_2',\n",
    "#       'datodHCat_3', 'datodHCat_4', 'datodHCat_5', 'crimecount_x', '60']\n",
    "#data.loc[data.id==2882045,columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_ids = [\"all_data\"]\n",
    "Xs = [X_all]\n",
    "hyperparameters = {'ntrees':[10,30], 'max_depth':[10]}\n",
    "search_criteria = { 'strategy': \"RandomDiscrete\", 'seed': 42,\n",
    "            'stopping_metric': \"AUC\", 'stopping_tolerance': 0.1,\n",
    "            'stopping_rounds': 2}\n",
    "setting = \"grid\"\n",
    "model_id = \"drf\"\n",
    "\n",
    "for i in range(len(data_ids)):\n",
    "    data_id = data_ids[i]\n",
    "    X = Xs[i]\n",
    "    model = H2ORandomForestEstimator(model_id = model_id+\"_\"+data_id)\n",
    "    models = grid_search(model, hyperparameters, search_criteria, X, model_id+\"_\"+data_id+\"_grid\")\n",
    "    for j in range(3):\n",
    "        if data_id == \"all_data\":\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X, True, 30)\n",
    "        else:\n",
    "            train_test_model_save_results_h2o(models[j], model_id+str(j)+\"_\"+setting, data_id, X)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
